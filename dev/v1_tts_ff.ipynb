{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a British computer scientist, entrepreneur, essayist, and venture capitalist. He is best known as a co-founder of Y Combinator, a startup accelerator that has helped launch many successful technology companies. In addition to his work with startups, Graham is widely read for his influential essays on programming, technology, entrepreneurship, and the nature of innovation. Earlier in his career, he co-founded Viaweb—which was later acquired by Yahoo!—and made significant contributions to the programming language community through his advocacy of languages like Lisp. His writings and ventures have had a lasting impact on Silicon Valley and the broader tech ecosystem.\n",
      "Paul Graham is an influential computer scientist, entrepreneur, and venture capitalist, best known for his work in the field of programming languages and for co-founding the startup accelerator Y Combinator. He is also recognized for his essays on technology, startups, and entrepreneurship, which have garnered a significant following. Graham co-authored the programming language Lisp and has been involved in various startups, including Viaweb, which was one of the first web-based applications and was acquired by Yahoo! in 1998. His insights on startups and innovation have made him a prominent figure in the tech community.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "import os \n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")  # Default to \"us-east-1\" if not set\n",
    "open_ai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "llm_openai_4o_128k = OpenAI(model=\"gpt-4o-mini\", api_key=open_ai_key,max_tokens=16384,temperature=0)\n",
    "\n",
    "llm_openai_o3_200k = OpenAI(model=\"o3-mini-2025-01-31\", api_key=open_ai_key,max_tokens=100000,temperature=0)\n",
    "\n",
    "print(llm_openai_o3_200k.complete(\"Paul Graham is \"))\n",
    "print(llm_openai_4o_128k.complete(\"Paul Graham is \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")  # Default to \"us-east-1\" if not set\n",
    "open_ai_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.llms.bedrock import Bedrock\n",
    "\n",
    "llm_claude_3_5_200k = Bedrock(\n",
    "    model=\"us.anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name=AWS_REGION,\n",
    "    temperature=0,\n",
    "    context_size=200000,\n",
    "    max_tokens=4096,\n",
    ")\n",
    "\n",
    "llm_mistral_large_32k = Bedrock(\n",
    "    model=\"mistral.mistral-large-2402-v1:0\",\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name=AWS_REGION,\n",
    "    temperature=0,\n",
    "    context_size=32000,\n",
    "    max_tokens=8192,\n",
    "    additional_kwargs={\n",
    "        \"top_p\": 1.0, \n",
    "        \"top_k\": 50    \n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# print(llm_claude_3_5_200k.complete(\"Paul Graham is\"))\n",
    "\n",
    "\n",
    "# print(llm_mistral_large_32k.complete(\"Paul Graham is \"))\n",
    "\n",
    "\n",
    "llm_meta_3_3_128k = Bedrock(\n",
    "    model=\"us.meta.llama3-3-70b-instruct-v1:0\",\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name=AWS_REGION,\n",
    "    temperature=0,\n",
    "    context_size=128000,\n",
    "    max_tokens=2048,\n",
    "    additional_kwargs={\n",
    "        \"top_p\": 1.0,  # Ensuring all options are considered\n",
    "    }     \n",
    "    )\n",
    "\n",
    "# print(llm_meta_3_3_128k.complete(\"Paul Graham is \"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy import create_engine, inspect, text\n",
    "\n",
    "# database_url = \"mysql+pymysql://golgix:preciseV5@143.198.230.83:3306/golgixportal\"\n",
    "# engine = create_engine(database_url)\n",
    "\n",
    "def get_first_row_with_types(inspector, tables):\n",
    "    result_str = \"\"\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        for table in tables:\n",
    "            if table in inspector.get_table_names():\n",
    "                # Get column details\n",
    "                columns = inspector.get_columns(table)\n",
    "                column_info = {col[\"name\"]: str(col[\"type\"]) for col in columns}\n",
    "                \n",
    "                # Get first row data\n",
    "                query = text(f\"SELECT * FROM `{table}` LIMIT 1\")\n",
    "                row = conn.execute(query).fetchone()\n",
    "                \n",
    "                # Format results as string\n",
    "                result_str += f\"Table: {table}\\n\"\n",
    "                result_str += f\"Columns and Data Types: {column_info}\\n\"\n",
    "                result_str += f\"First Row: {dict(zip(column_info.keys(), row)) if row else None}\\n\"\n",
    "                result_str += \"-\" * 50 + \"\\n\"\n",
    "    \n",
    "    return result_str\n",
    "\n",
    "# Example usage\n",
    "# inspector = inspect(engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: DE\n",
      "Columns and Data Types: {'recordid': 'INTEGER', 'datetime': 'DATETIME', 'date': 'DATE', 'shift': 'VARCHAR(50)', 'operator': 'VARCHAR(50)', 'hour': 'VARCHAR(100)', 'category': 'VARCHAR(50)', 'parameter': 'VARCHAR(50)', 'target': 'VARCHAR(50)', 'entered_value': 'VARCHAR(50)', 'user': 'VARCHAR(50)'}\n",
      "First Row: {'recordid': 34, 'datetime': datetime.datetime(2024, 12, 12, 5, 13, 27), 'date': datetime.date(2024, 12, 11), 'shift': 'B', 'operator': 'DYLAN EVANS_1', 'hour': '8:30', 'category': 'EVAP', 'parameter': 'Draw Pump', 'target': '4.9', 'entered_value': '5', 'user': 'admin'}\n",
      "--------------------------------------------------\n",
      "Table: HPLC_Data\n",
      "Columns and Data Types: {'Quarter': 'VARCHAR(10)', 'Ferm Drop Month': 'VARCHAR(20)', 'Ferm No': 'VARCHAR(10)', 'Batch No': 'VARCHAR(20)', 'Ferm Hour': 'VARCHAR(50)', 'Sample Description': 'VARCHAR(50)', 'Prop Mash % Solids': 'FLOAT', 'Prop Urea (lbs)': 'FLOAT', 'Prop Antibiotic (lbs)': 'FLOAT', 'Prop GA (gal)': 'FLOAT', 'Prop Protease (gal)': 'FLOAT', 'Ferm GA 1st Add. (gal)': 'FLOAT', 'Ferm GA 2nd Add (gal)': 'FLOAT', 'Ferm GA Flow (mL/min)': 'FLOAT', 'Ferm Fill Time (hrs)': 'FLOAT', 'GA Meter Add. (gal)': 'FLOAT', 'Total Ferm GA (gal)': 'FLOAT', 'Ferm AA Flow (mL/min)': 'FLOAT', 'Ferm AA (gal)': 'FLOAT', 'Ferm Protease (gal)': 'FLOAT', 'Ferm Phytase (gal)': 'FLOAT', 'Ferm Antibiotic (lbs)': 'FLOAT', 'Ferm Liq Urea (gal)': 'FLOAT', 'Ferm Prilled Urea (lbs)': 'FLOAT', 'First Yeast Addition (Boxes)': 'FLOAT', 'Second Yeast Addition (boxes)': 'FLOAT', 'Prop Start Date and Time': 'DATETIME', 'Start Fill Date and Time': 'DATETIME', 'Drop Date and Time': 'DATETIME', '% Backset to Ferm': 'FLOAT', 'Slurry Density (lbs/gal)': 'FLOAT', 'Liq Density (lbs/gal)': 'FLOAT', 'Prop hours': 'FLOAT', 'pH': 'FLOAT', 'Brix': 'FLOAT', 'Prop Temp (F)': 'FLOAT', 'Ferm Vessel Temp (F)': 'FLOAT', '% Budding': 'FLOAT', 'Cell Count': 'FLOAT', '% Viability': 'FLOAT', 'Total Cells Count (Calc)': 'FLOAT', 'Live Cells': 'FLOAT', 'Dead Cells': 'FLOAT', '% Viability (Calc)': 'FLOAT', '% DP4 (w/v)': 'FLOAT', '% DP3 (w/v)': 'FLOAT', '% DP2 (w/v)': 'FLOAT', '% Glucose (w/v)': 'FLOAT', '% Lactic Acid (w/v)': 'FLOAT', '% Glycerol (w/v)': 'FLOAT', '% Acetic Acid (w/v)': 'FLOAT', '% Ethanol (w/v)': 'FLOAT', '% Total Sugars (w/v)': 'FLOAT', 'Notes': 'TEXT'}\n",
      "First Row: {'Quarter': 'Q4', 'Ferm Drop Month': 'November', 'Ferm No': 'F1', 'Batch No': '8936', 'Ferm Hour': '5', 'Sample Description': 'PROP', 'Prop Mash % Solids': 19.85, 'Prop Urea (lbs)': 100.0, 'Prop Antibiotic (lbs)': 0.25, 'Prop GA (gal)': 0.5, 'Prop Protease (gal)': None, 'Ferm GA 1st Add. (gal)': 27.4, 'Ferm GA 2nd Add (gal)': 0.0, 'Ferm GA Flow (mL/min)': 0.0, 'Ferm Fill Time (hrs)': 13.75, 'GA Meter Add. (gal)': 0.0, 'Total Ferm GA (gal)': 27.4, 'Ferm AA Flow (mL/min)': 147.0, 'Ferm AA (gal)': 32.041, 'Ferm Protease (gal)': None, 'Ferm Phytase (gal)': 2.7, 'Ferm Antibiotic (lbs)': 2.0, 'Ferm Liq Urea (gal)': 733.0, 'Ferm Prilled Urea (lbs)': None, 'First Yeast Addition (Boxes)': 4.0, 'Second Yeast Addition (boxes)': None, 'Prop Start Date and Time': datetime.datetime(2024, 11, 6, 2, 30), 'Start Fill Date and Time': datetime.datetime(2024, 11, 6, 10, 30), 'Drop Date and Time': datetime.datetime(2024, 11, 8, 11, 30), '% Backset to Ferm': 14.0, 'Slurry Density (lbs/gal)': 9.33, 'Liq Density (lbs/gal)': 9.107, 'Prop hours': 8.0, 'pH': 5.04, 'Brix': 17.7, 'Prop Temp (F)': 89.6, 'Ferm Vessel Temp (F)': None, '% Budding': None, 'Cell Count': None, '% Viability': None, 'Total Cells Count (Calc)': 434.0, 'Live Cells': 368.0, 'Dead Cells': 66.0, '% Viability (Calc)': 0.847926, '% DP4 (w/v)': None, '% DP3 (w/v)': None, '% DP2 (w/v)': None, '% Glucose (w/v)': None, '% Lactic Acid (w/v)': None, '% Glycerol (w/v)': None, '% Acetic Acid (w/v)': None, '% Ethanol (w/v)': None, '% Total Sugars (w/v)': None, 'Notes': None}\n",
      "--------------------------------------------------\n",
      "Table: fermentation_data\n",
      "Columns and Data Types: {'id': 'INTEGER', 'age': 'VARCHAR(50)', 'date': 'VARCHAR(50)', 'am_pm': 'VARCHAR(25)', 'ph': 'VARCHAR(10)', 'brix': 'VARCHAR(10)', 'temp': 'VARCHAR(10)', 'total': 'VARCHAR(10)', 'live': 'VARCHAR(10)', 'dead': 'VARCHAR(10)', 'viability': 'VARCHAR(10)', 'dp4': 'VARCHAR(10)', 'dp3': 'VARCHAR(10)', 'dp2': 'VARCHAR(10)', 'glucose': 'VARCHAR(10)', 'total_sugars': 'VARCHAR(10)', 'lactic_acid': 'VARCHAR(10)', 'glycerol': 'VARCHAR(10)', 'acetic_acid': 'VARCHAR(10)', 'ethanol': 'VARCHAR(10)', 'tester_initials': 'VARCHAR(50)', 'notes': 'TEXT', 'date_of_start': 'VARCHAR(100)', 'time_of_start': 'VARCHAR(100)', 'batch_number': 'VARCHAR(100)', 'ferm_number': 'VARCHAR(100)'}\n",
      "First Row: {'id': 37, 'age': 'P-4', 'date': '1', 'am_pm': '', 'ph': '', 'brix': '', 'temp': '', 'total': '', 'live': '', 'dead': '', 'viability': '', 'dp4': '', 'dp3': '', 'dp2': '', 'glucose': '', 'total_sugars': '', 'lactic_acid': '', 'glycerol': '', 'acetic_acid': '', 'ethanol': '', 'tester_initials': '', 'notes': '', 'date_of_start': '2025-22-01', 'time_of_start': '01:02', 'batch_number': '123', 'ferm_number': '123'}\n",
      "--------------------------------------------------\n",
      "Table: plc_data_1\n",
      "Columns and Data Types: {'ID': 'INTEGER', 'Timestamp': 'DATETIME', 'Source_PLC': 'TEXT', 'AMM_3118_PV': 'DOUBLE', 'AMM_3118TOT_PV': 'DOUBLE', 'AMM_3128_PV': 'DOUBLE', 'AMM_3128TOT_PV': 'DOUBLE', 'AMM_3138_PV': 'DOUBLE', 'AMM_3138TOT_PV': 'DOUBLE', 'AMM_3148_PV': 'DOUBLE', 'AMM_3148TOT_PV': 'DOUBLE', 'DI_3130_PV': 'DOUBLE', 'FI_2402_PV': 'DOUBLE', 'FI_3150_PV': 'DOUBLE', 'FI_3155_PV': 'DOUBLE', 'FI_3610_PV': 'DOUBLE', 'FI_3801_PV': 'DOUBLE', 'FI_3802_PV': 'DOUBLE', 'FIC_3513_PV': 'DOUBLE', 'FIC_3513_SP': 'DOUBLE', 'FIC_3513_VL': 'DOUBLE', 'FIC_3801_PV': 'DOUBLE', 'FIC_3801_SP': 'DOUBLE', 'FIC_3801_VL': 'DOUBLE', 'FIC_3803_PV': 'DOUBLE', 'FIC_3803_SP': 'DOUBLE', 'FIC_3803_VL': 'DOUBLE', 'LI_3111_PV': 'DOUBLE', 'LI_3121_PV': 'DOUBLE', 'LI_3131_PV': 'DOUBLE', 'LI_3141_PV': 'DOUBLE', 'LI_3501_PV': 'DOUBLE', 'LI_3601_PV': 'DOUBLE', 'LIC_3801_PV': 'DOUBLE', 'LIC_3801_SP': 'DOUBLE', 'LIC_3801_VL': 'DOUBLE', 'pHIC_2402_PV': 'DOUBLE', 'pHIC_2402_SP': 'DOUBLE', 'pHIC_2402_VL': 'DOUBLE', 'pHIC_3501_PV': 'DOUBLE', 'pHIC_3501_SP': 'DOUBLE', 'pHIC_3501_VL': 'DOUBLE', 'PI_2402_PV': 'DOUBLE', 'PI_3801_PV': 'DOUBLE', 'TI_3112_PV': 'DOUBLE', 'TI_3113_PV': 'DOUBLE', 'TI_3122_PV': 'DOUBLE', 'TI_3123_PV': 'DOUBLE', 'TI_3132_PV': 'DOUBLE', 'TI_3133_PV': 'DOUBLE', 'TI_3142_PV': 'DOUBLE', 'TI_3143_PV': 'DOUBLE', 'TI_3501_PV': 'DOUBLE'}\n",
      "First Row: {'ID': 1, 'Timestamp': datetime.datetime(2024, 11, 24, 9, 28, 15), 'Source_PLC': 'plc_historian_db_1', 'AMM_3118_PV': 15.849609375, 'AMM_3118TOT_PV': 19.81201171875, 'AMM_3128_PV': 16.95027732849121, 'AMM_3128TOT_PV': 17.17041015625, 'AMM_3138_PV': None, 'AMM_3138TOT_PV': None, 'AMM_3148_PV': 25.09521484375, 'AMM_3148TOT_PV': 27.4066162109375, 'DI_3130_PV': None, 'FI_2402_PV': 678.6475219726562, 'FI_3150_PV': None, 'FI_3155_PV': 642.8986206054688, 'FI_3610_PV': -0.002201080322265625, 'FI_3801_PV': None, 'FI_3802_PV': 75.16288757324219, 'FIC_3513_PV': 585.4341430664062, 'FIC_3513_SP': 585.0, 'FIC_3513_VL': 68.8689956665039, 'FIC_3801_PV': 0.1739025115966797, 'FIC_3801_SP': 10.0, 'FIC_3801_VL': 0.0, 'FIC_3803_PV': 45.0145263671875, 'FIC_3803_SP': 45.0, 'FIC_3803_VL': 86.82141876220703, 'LI_3111_PV': 88.7095947265625, 'LI_3121_PV': 73.41251373291016, 'LI_3131_PV': 9.008627891540527, 'LI_3141_PV': 87.0737075805664, 'LI_3501_PV': 59.39183807373047, 'LI_3601_PV': 67.67308807373047, 'LIC_3801_PV': 40.131927490234375, 'LIC_3801_SP': 40.0, 'LIC_3801_VL': 55.33071517944336, 'pHIC_2402_PV': 5.14229154586792, 'pHIC_2402_SP': 4.699999809265137, 'pHIC_2402_VL': 100.0, 'pHIC_3501_PV': 4.381702899932861, 'pHIC_3501_SP': 5.0, 'pHIC_3501_VL': 13.0, 'PI_2402_PV': 52.90748977661133, 'PI_3801_PV': 9.678810119628906, 'TI_3112_PV': 85.20062255859375, 'TI_3113_PV': 65.28982543945312, 'TI_3122_PV': 89.2398452758789, 'TI_3123_PV': 65.16073608398438, 'TI_3132_PV': 90.2811508178711, 'TI_3133_PV': 91.61457824707031, 'TI_3142_PV': 85.01476287841797, 'TI_3143_PV': 65.31922912597656, 'TI_3501_PV': 91.72306823730469}\n",
      "--------------------------------------------------\n",
      "Table: plc_data_2\n",
      "Columns and Data Types: {'ID': 'INTEGER', 'Timestamp': 'DATETIME', 'Source_PLC': 'TEXT', 'TI_3801_PV': 'DOUBLE', 'TIC_3111_EXT_PV': 'DOUBLE', 'TIC_3111_EXT_SP': 'DOUBLE', 'TIC_3111_EXT_VL': 'DOUBLE', 'TIC_3111B_EXT_PV': 'DOUBLE', 'TIC_3111B_EXT_SP': 'DOUBLE', 'TIC_3111B_EXT_VL': 'DOUBLE', 'TIC_3121_EXT_PV': 'DOUBLE', 'TIC_3121_EXT_SP': 'DOUBLE', 'TIC_3121_EXT_VL': 'DOUBLE', 'TIC_3121B_EXT_PV': 'DOUBLE', 'TIC_3121B_EXT_SP': 'DOUBLE', 'TIC_3121B_EXT_VL': 'DOUBLE', 'TIC_3131_EXT_PV': 'DOUBLE', 'TIC_3131_EXT_SP': 'DOUBLE', 'TIC_3131_EXT_VL': 'DOUBLE', 'TIC_3131B_EXT_PV': 'DOUBLE', 'TIC_3131B_EXT_SP': 'DOUBLE', 'TIC_3131B_EXT_VL': 'DOUBLE', 'TIC_3141_EXT_PV': 'DOUBLE', 'TIC_3141_EXT_SP': 'DOUBLE', 'TIC_3141_EXT_VL': 'DOUBLE', 'TIC_3141B_EXT_PV': 'DOUBLE', 'TIC_3141B_EXT_SP': 'DOUBLE', 'TIC_3141B_EXT_VL': 'DOUBLE', 'TIC_3601_PV': 'DOUBLE', 'TIC_3601_SP': 'DOUBLE', 'TIC_3601_VL': 'DOUBLE', 'TIC_3602_PV': 'DOUBLE', 'TIC_3602_SP': 'DOUBLE', 'TIC_3602_VL': 'DOUBLE', 'DT_2203_PV': 'DOUBLE', 'TI_9803_PV': 'DOUBLE', 'DT_2402_PV': 'DOUBLE', 'LI_2101_PV': 'DOUBLE', 'LI_2112_PV': 'DOUBLE', 'LI_6801_PV': 'DOUBLE', 'LI_6101_PV': 'DOUBLE', 'LI_6810_PV': 'DOUBLE', 'SC_1401_PV': 'DOUBLE', 'PT_1422_PV': 'DOUBLE', 'FI_1401_PV': 'DOUBLE', 'SIC_11301_OUT': 'DOUBLE', 'CD_11301_PV': 'DOUBLE', 'FT_11301_PV': 'DOUBLE', 'PT_7917_PV': 'DOUBLE', 'PT_1313_PV': 'DOUBLE', 'CWTOT': 'DOUBLE', 'DI_2203_PV': 'DOUBLE', 'FT_2203_PV': 'DOUBLE', 'FIC_2806_PV': 'DOUBLE'}\n",
      "First Row: {'ID': 1, 'Timestamp': datetime.datetime(2024, 11, 24, 9, 28, 15), 'Source_PLC': 'plc_historian_db_2', 'TI_3801_PV': 87.40239715576172, 'TIC_3111_EXT_PV': 91.13001251220703, 'TIC_3111_EXT_SP': 92.0, 'TIC_3111_EXT_VL': 60.32427215576172, 'TIC_3111B_EXT_PV': 91.13001251220703, 'TIC_3111B_EXT_SP': 92.0, 'TIC_3111B_EXT_VL': 0.0, 'TIC_3121_EXT_PV': 92.74431610107422, 'TIC_3121_EXT_SP': 92.0, 'TIC_3121_EXT_VL': 20.7485408782959, 'TIC_3121B_EXT_PV': 92.74431610107422, 'TIC_3121B_EXT_SP': 92.0, 'TIC_3121B_EXT_VL': -3.299999952316284, 'TIC_3131_EXT_PV': 91.56689453125, 'TIC_3131_EXT_SP': 92.0, 'TIC_3131_EXT_VL': -3.299999952316284, 'TIC_3131B_EXT_PV': 91.56689453125, 'TIC_3131B_EXT_SP': 92.0, 'TIC_3131B_EXT_VL': -1.677860140800476, 'TIC_3141_EXT_PV': 91.66232299804688, 'TIC_3141_EXT_SP': 92.0, 'TIC_3141_EXT_VL': 66.47895050048828, 'TIC_3141B_EXT_PV': 91.66232299804688, 'TIC_3141B_EXT_SP': 92.0, 'TIC_3141B_EXT_VL': 0.0, 'TIC_3601_PV': 89.55223846435547, 'TIC_3601_SP': 90.0, 'TIC_3601_VL': 33.62486267089844, 'TIC_3602_PV': 67.15277862548828, 'TIC_3602_SP': 92.0, 'TIC_3602_VL': 0.0, 'DT_2203_PV': 9.372385025024414, 'TI_9803_PV': 41.45833206176758, 'DT_2402_PV': 8.996292114257812, 'LI_2101_PV': 70.84345245361328, 'LI_2112_PV': 39.644752502441406, 'LI_6801_PV': 38.498958587646484, 'LI_6101_PV': 37.7017936706543, 'LI_6810_PV': 19.23277473449707, 'SC_1401_PV': None, 'PT_1422_PV': 8.724212646484375, 'FI_1401_PV': 28.670242309570312, 'SIC_11301_OUT': 38.0, 'CD_11301_PV': None, 'FT_11301_PV': 43.42454528808594, 'PT_7917_PV': 1.7532196044921875, 'PT_1313_PV': 4.819541931152344, 'CWTOT': 189259488.0, 'DI_2203_PV': None, 'FT_2203_PV': 86.2052001953125, 'FIC_2806_PV': 158.42652893066406}\n",
      "--------------------------------------------------\n",
      "Table: plc_data_3\n",
      "Columns and Data Types: {'ID': 'INTEGER', 'Timestamp': 'DATETIME', 'Source_PLC': 'TEXT', 'TIC_2203_PV': 'DOUBLE', 'FIC_024310B_PV': 'DOUBLE', 'II_2261_PV': 'DOUBLE', 'II_2262_PV': 'DOUBLE', 'TI_2204_PV': 'DOUBLE', 'FI_2204_PV': 'DOUBLE', 'LIC_2403_PV': 'DOUBLE', 'DIC_2402_PV': 'DOUBLE', 'FIC_70101_PV': 'DOUBLE', 'FIC_70102_PV': 'DOUBLE', 'FT_70103_PV': 'DOUBLE', 'FIC_70302_PV': 'DOUBLE', 'FT_70303_PV': 'DOUBLE', 'FIC_70502_PV': 'DOUBLE', 'FIC_6220_PV': 'DOUBLE', 'FIC_70107_PV': 'DOUBLE', 'FIC_70505_PV': 'DOUBLE', 'FT_70503_PV': 'DOUBLE', 'PT_S_PIT_PV': 'DOUBLE', 'ST_70801_PV': 'DOUBLE', 'TIC_2405_PV': 'DOUBLE', 'TIC_2408_PV': 'DOUBLE', 'FIC_2815_PV': 'DOUBLE', 'FIC_12415_PV': 'DOUBLE', 'FERM_GAP_TOT': 'DOUBLE', 'TIC_3601_PV': 'DOUBLE', 'FIC_4107_PV': 'DOUBLE', 'PI_4107_PV': 'DOUBLE', 'LIC_4204_VL': 'DOUBLE', 'FIC_4215_PV': 'DOUBLE', 'FI_6801_PV': 'DOUBLE', 'TI_4410_PV': 'DOUBLE', 'TI_4401_PV': 'DOUBLE', 'TI_DIFF_PV': 'DOUBLE', 'TI_SSDIFF_PV': 'DOUBLE', 'TI_4414_PV': 'DOUBLE', 'TV_2304_PV': 'DOUBLE', 'RECTDIFTMP': 'DOUBLE', 'PI_4501_PV': 'DOUBLE', 'PIC_4511_PV': 'DOUBLE', 'DTFIC_4506_S_PV': 'DOUBLE', 'FI_4505_PV': 'DOUBLE', 'PIC_4621_PV': 'DOUBLE', 'TI_4620_PV': 'DOUBLE', 'FIC_8401_PV': 'DOUBLE', 'TI_4619_PV': 'DOUBLE', 'FI_4613_PV': 'DOUBLE', 'LI_8401_PV': 'DOUBLE', 'LI_8422_PV': 'DOUBLE', 'LI_8433_PV': 'DOUBLE', 'II_6202_PV': 'DOUBLE'}\n",
      "First Row: {'ID': 1, 'Timestamp': datetime.datetime(2024, 11, 24, 9, 28, 15), 'Source_PLC': 'plc_historian_db_3', 'TIC_2203_PV': 184.99826049804688, 'FIC_024310B_PV': 999.7642822265625, 'II_2261_PV': 99.23944854736328, 'II_2262_PV': 239.43362426757812, 'TI_2204_PV': 182.28244018554688, 'FI_2204_PV': 846.1301879882812, 'LIC_2403_PV': 88.99951171875, 'DIC_2402_PV': 9.121980667114258, 'FIC_70101_PV': 806.726318359375, 'FIC_70102_PV': 406.7958984375, 'FT_70103_PV': 566.4873046875, 'FIC_70302_PV': 283.88385009765625, 'FT_70303_PV': 375.4959716796875, 'FIC_70502_PV': 183.07537841796875, 'FIC_6220_PV': 0.0, 'FIC_70107_PV': 48.622650146484375, 'FIC_70505_PV': 165.3280029296875, 'FT_70503_PV': 304.0042724609375, 'PT_S_PIT_PV': 2.444999933242798, 'ST_70801_PV': 0.5, 'TIC_2405_PV': 135.81468200683594, 'TIC_2408_PV': 91.7824935913086, 'FIC_2815_PV': -0.1584930419921875, 'FIC_12415_PV': 3222.1533203125, 'FERM_GAP_TOT': 337.5108947753906, 'TIC_3601_PV': None, 'FIC_4107_PV': 22738.158203125, 'PI_4107_PV': 13.716814994812012, 'LIC_4204_VL': 0.0, 'FIC_4215_PV': 47.38927459716797, 'FI_6801_PV': 223.19935607910156, 'TI_4410_PV': 150.88449096679688, 'TI_4401_PV': 183.46075439453125, 'TI_DIFF_PV': 7.13836669921875, 'TI_SSDIFF_PV': 15.269821166992188, 'TI_4414_PV': 174.95223999023438, 'TV_2304_PV': 0.0, 'RECTDIFTMP': 7.2239532470703125, 'PI_4501_PV': 6.717584133148193, 'PIC_4511_PV': 4.657867431640625, 'DTFIC_4506_S_PV': 148.32139587402344, 'FI_4505_PV': 97.15228271484375, 'PIC_4621_PV': 41.796875, 'TI_4620_PV': 310.1892395019531, 'FIC_8401_PV': 111.8814697265625, 'TI_4619_PV': 276.8135986328125, 'FI_4613_PV': 92.32772064208984, 'LI_8401_PV': 20.417617797851562, 'LI_8422_PV': 32.60416793823242, 'LI_8433_PV': 48.70682907104492, 'II_6202_PV': None}\n",
      "--------------------------------------------------\n",
      "Table: plc_data_4\n",
      "Columns and Data Types: {'ID': 'INTEGER', 'Timestamp': 'DATETIME', 'Source_PLC': 'TEXT', 'FIC_6202_PV': 'DOUBLE', 'C2_DIFF_SPD': 'DOUBLE', 'C2_TORQ': 'DOUBLE', 'II_6203_PV': 'DOUBLE', 'FIC_6203_PV': 'DOUBLE', 'C3_DIFF_SPD': 'DOUBLE', 'C3_TORQ': 'DOUBLE', 'IT_6254_PV': 'DOUBLE', 'FIC_6254_PV': 'DOUBLE', 'C4_DIFF_SPD': 'DOUBLE', 'C4_TORQ': 'DOUBLE', 'FIC_161301_PV': 'DOUBLE', 'WT_161310_PV': 'DOUBLE', 'ZT_161310': 'DOUBLE', 'FIC_161351_PV': 'DOUBLE', 'WT_161360_PV': 'DOUBLE', 'ZT_161360': 'DOUBLE', 'LI_77101_PV': 'DOUBLE', 'LI_77102_PV': 'DOUBLE', 'FI_75802': 'DOUBLE', 'TI_7107_PV': 'DOUBLE', 'TI_7103_PV': 'DOUBLE', 'FI_7102_PV': 'DOUBLE', 'PIC_7102_PV': 'DOUBLE', 'TIC_7311_PV': 'DOUBLE', 'TIC_7311_OUT': 'DOUBLE', 'FT_7306_PV': 'DOUBLE', 'FIC_6811_PV': 'DOUBLE', 'TI_7772_PV': 'DOUBLE', 'TI_7775_PV': 'DOUBLE', 'PI_7751_PV': 'DOUBLE', 'TI_7872_PV': 'DOUBLE', 'TI_7875_PV': 'DOUBLE', 'PI_7851_PV': 'DOUBLE', 'LI_12101_PV': 'DOUBLE', 'LI_12501_PV': 'DOUBLE', 'LI_12410_PV': 'DOUBLE', 'STEAMPERBEER': 'DOUBLE', 'TOT_STM_PERGAL': 'DOUBLE', 'TOTALCOOKWATER': 'DOUBLE', 'FT_70304_PV': 'DOUBLE', 'FT_70504_PV': 'DOUBLE', 'FT4613TOT': 'DOUBLE', 'FIC_6851_PV': 'DOUBLE', 'PT_7930_PV': 'DOUBLE', 'TV_4414_PV': 'DOUBLE', 'DI_4215_PV': 'DOUBLE', 'HT_7311_PV': 'DOUBLE', 'RATE_1401_PV': 'DOUBLE', 'LI_8403_PV': 'DOUBLE', 'LI_2301_PV': 'DOUBLE', 'FT4620_STM': 'DOUBLE', 'FT4107_STM': 'DOUBLE', 'C2_BOWL_CURRENT': 'DOUBLE', 'C3_BOWL_CURRENT': 'DOUBLE', 'SIEVEEFFIC': 'DOUBLE', 'FT1401TOT': 'DOUBLE', 'FT11301TOT': 'DOUBLE', 'FT_70104_PV': 'DOUBLE', 'TV_4414_VL': 'DOUBLE', 'FI_2432_PV': 'DOUBLE', 'DTFT_2402_PV': 'DOUBLE'}\n",
      "First Row: {'ID': 1, 'Timestamp': datetime.datetime(2024, 11, 24, 9, 28, 15), 'Source_PLC': 'plc_historian_db_4', 'FIC_6202_PV': None, 'C2_DIFF_SPD': 6.537463665008545, 'C2_TORQ': 59.0, 'II_6203_PV': None, 'FIC_6203_PV': None, 'C3_DIFF_SPD': 7.995574951171875, 'C3_TORQ': 61.0, 'IT_6254_PV': 91.81381225585938, 'FIC_6254_PV': 159.78480529785156, 'C4_DIFF_SPD': 2.2707157135009766, 'C4_TORQ': 60.0, 'FIC_161301_PV': 163.20797729492188, 'WT_161310_PV': 9.22613525390625, 'ZT_161310': 333.0, 'FIC_161351_PV': 165.94784545898438, 'WT_161360_PV': 9.78094482421875, 'ZT_161360': 342.0, 'LI_77101_PV': 53.787353515625, 'LI_77102_PV': 79.3049545288086, 'FI_75802': 5.245858192443848, 'TI_7107_PV': 202.70738220214844, 'TI_7103_PV': 201.77113342285156, 'FI_7102_PV': 20218.865234375, 'PIC_7102_PV': 45.08850860595703, 'TIC_7311_PV': 213.3822021484375, 'TIC_7311_OUT': 45.572166442871094, 'FT_7306_PV': 26.553466796875, 'FIC_6811_PV': 31.061290740966797, 'TI_7772_PV': 1601.0, 'TI_7775_PV': 362.0, 'PI_7751_PV': -3.1000000000000014, 'TI_7872_PV': 1625.2864990234375, 'TI_7875_PV': 281.0, 'PI_7851_PV': -3.1150975227355957, 'LI_12101_PV': 51.450408935546875, 'LI_12501_PV': 73.00817108154297, 'LI_12410_PV': 69.38704681396484, 'STEAMPERBEER': 38.839820861816406, 'TOT_STM_PERGAL': None, 'TOTALCOOKWATER': 253.8022918701172, 'FT_70304_PV': None, 'FT_70504_PV': None, 'FT4613TOT': None, 'FIC_6851_PV': None, 'PT_7930_PV': None, 'TV_4414_PV': None, 'DI_4215_PV': None, 'HT_7311_PV': None, 'RATE_1401_PV': None, 'LI_8403_PV': None, 'LI_2301_PV': None, 'FT4620_STM': None, 'FT4107_STM': None, 'C2_BOWL_CURRENT': None, 'C3_BOWL_CURRENT': None, 'SIEVEEFFIC': None, 'FT1401TOT': None, 'FT11301TOT': None, 'FT_70104_PV': None, 'TV_4414_VL': None, 'FI_2432_PV': None, 'DTFT_2402_PV': None}\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SQLDatabase\n",
    "# from sqlalchemy import create_engine\n",
    "from dataclasses import dataclass, field\n",
    "from sqlalchemy import inspect, text\n",
    "\n",
    "# Configuration for the database\n",
    "@dataclass\n",
    "class Config:\n",
    "    DB_HOST: str = \"143.198.230.83\"\n",
    "    DB_PORT: int = 3306\n",
    "    DB_NAME: str = \"golgixportal\"\n",
    "    DB_USER: str = \"golgix\"\n",
    "    DB_PASSWORD: str = \"preciseV5\"\n",
    "    ALLOWED_TABLES: list[str] = field(default_factory=lambda: [\n",
    "        \"DE\",\n",
    "        \"HPLC_Data\",\n",
    "        \"fermentation_data\",\n",
    "        \"plc_data_1\",\n",
    "        \"plc_data_2\",\n",
    "        \"plc_data_3\",\n",
    "        \"plc_data_4\"\n",
    "    ])\n",
    "\n",
    "# Load configuration\n",
    "config = Config()\n",
    "\n",
    "# Setup the SQLAlchemy engine URI\n",
    "db_uri = f\"mysql+pymysql://{config.DB_USER}:{config.DB_PASSWORD}@{config.DB_HOST}:{config.DB_PORT}/{config.DB_NAME}\"\n",
    "\n",
    "# Initialize the SQLDatabase with the URI and include_tables parameter\n",
    "sql_database = SQLDatabase.from_uri(db_uri, include_tables=config.ALLOWED_TABLES)\n",
    "engine = sql_database.engine\n",
    "inspector = inspect(engine)\n",
    "\n",
    "include_tables = [\"DE\", \"HPLC_Data\", \"fermentation_data\", \"plc_data_1\", \"plc_data_2\", \"plc_data_3\", \"plc_data_4\"]\n",
    "database_schema = get_first_row_with_types(inspector, include_tables)\n",
    "print(database_schema)\n",
    "# print(len(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CellometerSync', 'DE', 'DE_targets', 'HPLCSync', 'HPLC_Data', 'NIRSync', 'NIR_Data', 'QC', 'QC_targets', 'ab_permission', 'ab_permission_view', 'ab_permission_view_role', 'ab_register_user', 'ab_role', 'ab_user', 'ab_user_role', 'ab_view_menu', 'actual_output', 'alembic_version', 'annotation', 'annotation_layer', 'batch_info_table', 'cache_keys', 'cooks', 'cookshift_comments', 'css_templates', 'dashboard_roles', 'dashboard_slices', 'dashboard_user', 'dashboards', 'database_user_oauth2_tokens', 'dbs', 'de_comments', 'downtime_results', 'dynamic_plugin', 'embedded_dashboards', 'extended_table_to_edit_and_delete', 'fact_finder', 'favstar', 'feature_flag', 'fermentation_batch', 'fermentation_batch_comments', 'fermentation_data', 'inference_output', 'inference_output_deployed_19_02_25', 'key_value', 'keyvalue', 'logs', 'ml_output', 'operators', 'pf_comments', 'plc_categories', 'plc_data_1', 'plc_data_2', 'plc_data_3', 'plc_data_4', 'plc_ips', 'plc_tags', 'predictions', 'propagator_and_fermenter', 'qc_comments', 'query', 'reduced_rate_results', 'report_execution_log', 'report_recipient', 'report_schedule', 'report_schedule_user', 'rls_filter_roles', 'rls_filter_tables', 'row_level_security_filters', 'saved_query', 'shifts', 'shifts1', 'slice_user', 'slices', 'sql_metrics', 'sqlatable_user', 'ssh_tunnels', 'tab_state', 'table_columns', 'table_schema', 'tables', 'tag', 'tagged_object', 'targets', 'user_attribute', 'user_favorite_tag', 'walkthroughs']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "\n",
    "def get_table_list(sql_database):\n",
    "    \"\"\"Returns a list of all tables in the database.\"\"\"\n",
    "    engine = sql_database.engine  # Extract engine from SQLDatabase\n",
    "    inspector = inspect(engine)\n",
    "    \n",
    "    return inspector.get_table_names()\n",
    "\n",
    "# Example usage\n",
    "table_list = get_table_list(sql_database)\n",
    "print(table_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sufficient': True, 'question': 'None', 'Assumption': \"We assume that the fermentation process metrics are stored in the HPLC_Data table. In particular, the last fermentation batch is identified as the record with the latest 'Drop Date and Time' (prior to the current time of 2025-02-25 07:28:18.911284). The columns '% Ethanol (w/v)', '% Total Sugars (w/v)', '% Lactic Acid (w/v)', '% Acetic Acid (w/v)', 'pH', and 'Prop Temp (F)' in HPLC_Data are assumed to represent the fermentation metrics requested. In addition, no join is needed between tables as the required fermentation outcome data is consolidated in HPLC_Data.\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from llama_index.core import PromptTemplate\n",
    "import datetime\n",
    "\n",
    "CLARIFICATION_PROMPT = PromptTemplate(\"\"\"\\\n",
    "You are a SQL optimization engineer with deep domain knowledge of industrial equipment systems. Follow this analysis process:\n",
    "\n",
    "1. Schema Mapping:\n",
    "- Identify required tables and the first row of the data from: {schema}\n",
    "- Locate exact column matches for equipment IDs, timestamps, and metrics and understand the meaning based on just the first row given \n",
    "- Verify join paths using foreign keys\n",
    "\n",
    "2. Domain Validation:\n",
    "- Cross-reference {domain_knowledge} thresholds\n",
    "- Confirm failure state calculations align with domain logic\n",
    "\n",
    "3. Join Requirement Check:\n",
    "- Determine if question requires combining operational metrics\n",
    "- Validate time synchronization between tables if joining\n",
    "\n",
    "For question: {question}\n",
    "\n",
    "Additional Context:\n",
    "- current data time {date}\n",
    "- A SQL engine is available to execute the query and get rest of the data from the tables \n",
    "- If any information is missing or unclear, specify exactly what is needed.\n",
    "\n",
    "Response Rules:\n",
    "- Return **ONLY valid JSON** with the following structure:\n",
    "  - If sufficient information:\n",
    "    {{\n",
    "      \"sufficient\": true,\n",
    "      \"question\":  'None'\"\n",
    "      \"Assumption\":Your clear assumption\n",
    "    }}\n",
    "  - If insufficient information:\n",
    "    {{\n",
    "      \"sufficient\": false,\n",
    "      \"question\":  follow up question to generate proper query\n",
    "      \"Assumption\":Your clear assumption\n",
    "    }}\n",
    "\"\"\")\n",
    "\n",
    "def check_sql_feasibility(llm, question, schema, domain_knowledge, retry=5):\n",
    "    \"\"\"Checks if the given question has enough information to generate SQL.\"\"\"\n",
    "    for i in range(retry):\n",
    "      schema_str = str(schema)\n",
    "      date=datetime.datetime.now()\n",
    "      response = llm.complete(CLARIFICATION_PROMPT.format(\n",
    "          question=question,\n",
    "          schema=schema_str,\n",
    "          domain_knowledge=domain_knowledge,\n",
    "          date=date,\n",
    "      )).text.strip()\n",
    "\n",
    "      # Ensure the output is properly formatted JSON\n",
    "      try:\n",
    "          json_response = json.loads(response)\n",
    "          return json_response\n",
    "      except json.JSONDecodeError:\n",
    "          print(\"there was some error to convert into json retrying\")\n",
    "          print(response)\n",
    "          continue\n",
    "    return  {\n",
    "      \"sufficient\": None,\n",
    "      \"question\":  None,\n",
    "      \"Assumption\":None,\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "# question = \"Tell me total time duration dryer was down in last 7 days equipment_id PT_7930-PV\"\n",
    "# question =\"Downtime on equipment last 24 hours\"\n",
    "# question =\"How many loads of ethanol do we have? Is there a COA completed for the other storage tank.\"\n",
    "# question =\"Downtime on all the equipment in last 24 hours\"\n",
    "# question=\"What is the current water balance of the plant.\"\n",
    "# question=\"Are there any deviations from the normal chemical usage levels\"\n",
    "question =\"How is Fermentation doing, % ethanol, % total sugars, % lactic acid, % acetic acid, pH and temperature in last batch\"\n",
    "\n",
    "domain_knowledge = \"\"\"\n",
    "PT_7930-PV – DDG suction pressure.  Normal range is -1.9, if suction drops to above -1.0, dryers are down.\n",
    "FIC_70101-PV – FST feed.  Normal range is ~750gpm; low deviation of 20% indicates reduced rate, value of <100 FST is down.\n",
    "FIC_024310B-PV – SMT feed. Normal range is ~1000gpm. Low deviation of 20% indicates reduced rate, value of <100 SMT is down.\n",
    "FIC_6851-PV – Tricanter feed.  Normal range is 60gpm. Low deviation of 20% indicates reduced rate, value of <10gpm tricanter is down.\n",
    "FIC_161351-PV  – Sedicanter feed.  Normal range is 160gpm, Low deviation of 20% indicates reduced rate, value of <50gpm sedicanters down.\n",
    "FI_4505-PV – 190 flow to storage – Normal range is 110gpm.  Low deviation of 20% indicates reduced rate, value of <20gpm distillation down.\n",
    "FIC_8401-PV – Mole sieve feed rate – Normal range is 110gpm. Low deviation of 20% indicates reduced rate, value of <20gpm Mole sieves down.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Run feasibility check\n",
    "llm=llm_openai_o3_200k\n",
    "response_json = check_sql_feasibility(llm, question, database_schema, domain_knowledge)\n",
    "# response_json = json.loads(check_sql_feasibility(llm, question, database_schema, domain_knowledge))\n",
    "print(response_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_json['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_rephrase_helper(llm, prev_question, prev_feedback, response):      \n",
    "    combine_prompt = f\"\"\"\n",
    "Combine the following into a single, clear to the point question:\n",
    "\n",
    "Original Question: {prev_question}\n",
    "Clarifying Question: {prev_feedback}\n",
    "User's Answer: {response}\n",
    "\n",
    "Rules:\n",
    "1. Preserve the intent of the original question.\n",
    "2. Incorporate the user's answer explicitly.\n",
    "3. Make the question self-contained and unambiguous.\n",
    "4. Return **ONLY valid JSON** in this format:\n",
    "{{\n",
    "    \"question\": \"Your rephrased question here\"\n",
    "}}\n",
    "\n",
    "\"\"\"\n",
    "    result = llm.complete(combine_prompt).text.strip()\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "# llm1 =llm_mistral_large_32k\n",
    "# rephrase_que = json.loads(handle_rephrase_helper(\n",
    "#     llm=llm1,\n",
    "#     prev_question=question,\n",
    "#     prev_feedback=response_json['question'],\n",
    "#     response=\"the amount of ethanol being transported or processed in a given system\"\n",
    "# ))\n",
    "# print(rephrase_que[\"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json.loads(check_sql_feasibility(llm, rephrase_que[\"question\"], database_schema, domain_knowledge)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core.workflow import (\n",
    "#     InputRequiredEvent,\n",
    "#     HumanResponseEvent,\n",
    "#     Workflow,\n",
    "#     step,\n",
    "#     StopEvent,\n",
    "#     StartEvent,\n",
    "#     Context\n",
    "# )\n",
    "\n",
    "# # Define custom events with proper typing\n",
    "# class ValidatedQuestionEvent(HumanResponseEvent):\n",
    "#     pass\n",
    "\n",
    "# # Remove the instruction field if not needed, or make it optional\n",
    "# class CustomInputQuestion(InputRequiredEvent):\n",
    "#     # Inherits prefix: str from InputRequiredEvent\n",
    "#     pass  # Removed instruction field since it's not used\n",
    "\n",
    "# class AdditionlInfo(InputRequiredEvent):\n",
    "#     pass\n",
    "\n",
    "# class RephraseQuestion(HumanResponseEvent):\n",
    "#     pass\n",
    "\n",
    "# class question_validate_wf(Workflow):\n",
    "#     def __init__(self, llm1,llm2, schema, domain_knowledge,debug=True):\n",
    "#         # Remove the self.ctx.set() call from here\n",
    "#         super().__init__(timeout=300, verbose=True)\n",
    "#         self.llm1 = llm1\n",
    "#         self.llm2 = llm2\n",
    "#         self.schema = schema\n",
    "#         self.domain_knowledge = domain_knowledge\n",
    "#         self.debug=debug\n",
    "#     @step\n",
    "#     async def get_question(self, ev: StartEvent) -> CustomInputQuestion:\n",
    "#         return CustomInputQuestion(prefix=\"Enter your question: \")  # Now valid\n",
    "    \n",
    "#     @step\n",
    "#     async def validate_question(self,ctx: Context, ev: ValidatedQuestionEvent) -> StopEvent|AdditionlInfo:\n",
    "#         if self.debug:\n",
    "#             print(\"question :\",ev.response)\n",
    "#         await ctx.set(\"original_question\",ev.response)\n",
    "#         # print(\"schema :\",self.schema)\n",
    "#         # print(\"domain :\",self.domain_knowledge)\n",
    "#         response_json=json.loads(check_sql_feasibility(self.llm1, ev.response, self.schema, self.domain_knowledge))\n",
    "#         # print(type(response_json[\"sufficient\"]),response_json[\"sufficient\"])\n",
    "#         await ctx.set(\"sufficient\",response_json[\"sufficient\"])\n",
    "#         await ctx.set(\"Assumption\",response_json[\"Assumption\"])\n",
    "#         await ctx.set(\"Follow_up_Question\",response_json[\"question\"])\n",
    "#         if response_json[\"sufficient\"]:\n",
    "#             if self.debug:\n",
    "#                 print(\"Enough data to create sql query\")\n",
    "#             return StopEvent(response_json[\"Assumption\"])\n",
    "#         else :\n",
    "#             if self.debug:\n",
    "#                 print(\"Not enough data to create sql query follow up question\")\n",
    "#             return AdditionlInfo(prefix=response_json[\"question\"])\n",
    "        \n",
    "#     @step\n",
    "#     async def handle_rephrase(self, ctx: Context,ev: RephraseQuestion) -> ValidatedQuestionEvent :\n",
    "#         # if self.debug:\n",
    "#         #     print(\"question :\",ev.response)\n",
    "#         prev_question = await ctx.get(\"original_question\")\n",
    "#         prev_feedback = await ctx.get(\"Follow_up_Question\")\n",
    "        \n",
    "#         rephrase_que = json.loads(handle_rephrase_helper(\n",
    "#             llm=self.llm2,\n",
    "#             prev_question=prev_question,\n",
    "#             prev_feedback=prev_feedback,\n",
    "#             response=ev.response,\n",
    "#         ))\n",
    "#         if self.debug:\n",
    "#             print(\"rephrased question :\",rephrase_que['question'])\n",
    "#         return ValidatedQuestionEvent(response=rephrase_que['question'])\n",
    "        \n",
    "\n",
    "# # Execution\n",
    "# workflow = question_validate_wf(llm_openai_o3_200k,llm_mistral_large_32k, database_schema, domain_knowledge)\n",
    "# handler = workflow.run()\n",
    "\n",
    "# async for event in handler.stream_events():\n",
    "#     if isinstance(event, CustomInputQuestion):\n",
    "#         response = input(event.prefix)\n",
    "#         # feedback = {\"valid\": True, \"message\": \"Valid question\"}\n",
    "        \n",
    "#         handler.ctx.send_event(\n",
    "#             ValidatedQuestionEvent(\n",
    "#                 response=response,\n",
    "#             )\n",
    "#         )\n",
    "#     elif isinstance(event, AdditionlInfo):\n",
    "#         response = input(event.prefix)\n",
    "#         # feedback = {\"valid\": True, \"message\": \"Valid question\"}\n",
    "        \n",
    "#         handler.ctx.send_event(\n",
    "#             RephraseQuestion(\n",
    "#                 response=response,\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "# final_result = await handler\n",
    "# print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core import PromptTemplate\n",
    "# from typing import List, Optional\n",
    "\n",
    "# sql_prompt = PromptTemplate(\"\"\"\\\n",
    "# Role: Expert SQL Engineer specializing in industrial equipment systems\n",
    "\n",
    "# Task: Generate accurate SQL query following this workflow:\n",
    "\n",
    "# 1. **Schema Analysis**:\n",
    "# - Identify required tables and its column and Use first row data to understand column meanings: {schema}\n",
    "# - Establish table relationships using foreign keys\n",
    "\n",
    "# 2. **Domain Validation**:\n",
    "# - Cross-check with industry specific knowledge:\n",
    "# {domain_knowledge}\n",
    "\n",
    "\n",
    "# 3. Error Avoidance:\n",
    "# - Previous failed queries: {prev_sql_list}\n",
    "# - Failure reasons: {prev_fail_reason}\n",
    "# - Actively avoid repeating these patterns\n",
    "\n",
    "# 4. Temporal Context:\n",
    "# - Current system datetime: {date}\n",
    "\n",
    "# **Query Requirements**:\n",
    "# - Use only tables in the schema\n",
    "# - Prioritize index-friendly operations\n",
    "# - Include necessary JOINs but avoid Cartesian products\n",
    "# - Handle NULL values appropriately\n",
    "\n",
    "# Current Task:\n",
    "# Question: {question}\n",
    "\n",
    "# Response Rules:\n",
    "# - Return **ONLY valid JSON** with the following structure:\n",
    "# {{\n",
    "#   \"query\": \"SELECT...\",\n",
    "#   \"rationale\": \"Brief technical justification\"\n",
    "# }}\n",
    "\n",
    "# \"\"\")\n",
    "\n",
    "# def generate_sql_query(\n",
    "#     llm,\n",
    "#     question: str,\n",
    "#     schema: str,\n",
    "#     domain_knowledge: str,\n",
    "#     prev_sql_list: Optional[List[str]] = None,\n",
    "#     prev_fail_reason: Optional[List[str]] = None,\n",
    "#     date: str = datetime.datetime.now()\n",
    "# ) -> dict:\n",
    "#     \"\"\"\n",
    "#     Generates SQL query using industrial equipment database schema\n",
    "#     \"\"\"\n",
    "#     # Format previous attempts for prompt\n",
    "#     prev_sql_str = \"\\n- \".join(prev_sql_list) if prev_sql_list else \"None\"\n",
    "#     prev_fail_str = \"\\n- \".join(prev_fail_reason) if prev_fail_reason else \"None\"\n",
    "\n",
    "#     formatted_prompt = sql_prompt.format(\n",
    "#         question=question,\n",
    "#         schema=schema,\n",
    "#         domain_knowledge=domain_knowledge,\n",
    "#         prev_sql_list=prev_sql_str,\n",
    "#         prev_fail_reason=prev_fail_str,\n",
    "#         date=date,\n",
    "#     )\n",
    "#     # print(formatted_prompt)\n",
    "#     return llm.complete(formatted_prompt).text.strip()\n",
    "#     # try:\n",
    "#         # result = json.loads(llm.complete(formatted_prompt).text)\n",
    "#     #     return {\n",
    "#     #         \"query\": result[\"query\"].strip(),\n",
    "#     #         \"rationale\": result.get(\"rationale\", \"\"),\n",
    "#     #         \"error\": None\n",
    "#     #     }\n",
    "#     # except Exception as e:\n",
    "#     #     return {\n",
    "#     #         \"query\": None,\n",
    "#     #         \"rationale\": None,\n",
    "#     #         \"error\": f\"Generation failed: {str(e)}\"\n",
    "#     #     }\n",
    "\n",
    "# # Usage example:\n",
    "# result = generate_sql_query(\n",
    "#     llm=llm_openai_o3_200k,\n",
    "#     question=\"Downtime on equipments in last 24 hours\",\n",
    "#     schema=database_schema,\n",
    "#     domain_knowledge=domain_knowledge,\n",
    "#     prev_sql_list=\"\",  # From previous attempts\n",
    "#     prev_fail_reason=\"\"  # Previous errors\n",
    "# )\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query=json.loads(result)['query']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy.exc import SQLAlchemyError\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "# max_rows=1000\n",
    "# try:\n",
    "#     with engine.connect() as conn:\n",
    "#         # Validate query safety\n",
    "#         if any(keyword in query.upper() for keyword in [\"DROP\", \"DELETE\", \"UPDATE\", \"INSERT\"]):\n",
    "#             raise ValueError(\"Modification queries are blocked\")\n",
    "\n",
    "#         # Execute and fetch results\n",
    "#         cursor = conn.execute(text(query))\n",
    "        \n",
    "#         if cursor.returns_rows:\n",
    "#             results = cursor.fetchmany(max_rows)\n",
    "#             row_count = len(results)\n",
    "#         else:\n",
    "#             results = None\n",
    "#             row_count = cursor.rowcount\n",
    "\n",
    "#         print ({\n",
    "#             \"query\": query,\n",
    "#             \"results\": results,\n",
    "#             \"error\": None,\n",
    "#             \"execution_time\": time.time() - start_time,\n",
    "#             \"row_count\": row_count\n",
    "#         })\n",
    "\n",
    "# except SQLAlchemyError as e:\n",
    "#     error_msg = f\"SQL Error [{type(e).__name__}]: {str(e)}\"\n",
    "#     print ({\n",
    "#         \"query\": query,\n",
    "#         \"results\": None,\n",
    "#         \"error\": error_msg,\n",
    "#         \"execution_time\": time.time() - start_time,\n",
    "#         \"row_count\": None\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "from typing import List, Optional\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import time\n",
    "\n",
    "# sql_prompt = PromptTemplate(\"\"\"\\\n",
    "# Role: Expert SQL Engineer specializing in industrial equipment systems\n",
    "\n",
    "# Task: Generate accurate SQL query following this workflow:\n",
    "\n",
    "# 1. **Schema Analysis**:\n",
    "# - Identify required tables and its column and Use first row data to understand column meanings: {schema}\n",
    "# - Establish table relationships using foreign keys\n",
    "\n",
    "# 2. **Domain Validation**:\n",
    "# - Cross-check with industry specific knowledge:\n",
    "# {domain_knowledge}\n",
    "\n",
    "\n",
    "# 3. Error Avoidance:\n",
    "# - Previous failed queries: {prev_sql_list}\n",
    "# - Failure reasons: {prev_fail_reason}\n",
    "# - Actively avoid repeating these patterns\n",
    "\n",
    "# 4. Temporal Context:\n",
    "# - Current system datetime: {date}\n",
    "\n",
    "# **Query Requirements**:\n",
    "# - Use only tables in the schema\n",
    "# - Prioritize index-friendly operations\n",
    "# - Include necessary JOINs but avoid Cartesian products\n",
    "# - Handle NULL values appropriately\n",
    "\n",
    "# Current Task:\n",
    "# Question: {question}\n",
    "\n",
    "# Response Rules:\n",
    "# - Return **ONLY valid JSON** with the following structure:\n",
    "# {{\n",
    "#   \"query\": \"SELECT...\",\n",
    "#   \"rationale\": \"Brief technical justification\"\n",
    "# }}\n",
    "\n",
    "# \"\"\")\n",
    "\n",
    "# def generate_sql_query(\n",
    "#     llm_engine,\n",
    "#     engine,\n",
    "#     question: str,\n",
    "#     schema: str,\n",
    "#     domain_knowledge: str,\n",
    "#     prev_sql_list: Optional[List[str]] = None,\n",
    "#     prev_fail_reason: Optional[List[str]] = None,\n",
    "#     date: str = datetime.datetime.now(),\n",
    "#     retry:int=4\n",
    "# ) -> dict:\n",
    "#     \"\"\"\n",
    "#     Generates SQL query using industrial equipment database schema\n",
    "#     \"\"\"\n",
    "#     # Format previous attempts for prompt\n",
    "#     prev_sql_str = \"\\n- \".join(prev_sql_list) if prev_sql_list else \"None\"\n",
    "#     prev_fail_str = \"\\n- \".join(prev_fail_reason) if prev_fail_reason else \"None\"\n",
    "\n",
    "#     formatted_prompt = sql_prompt.format(\n",
    "#         question=question,\n",
    "#         schema=schema,\n",
    "#         domain_knowledge=domain_knowledge,\n",
    "#         prev_sql_list=str(prev_sql_str),\n",
    "#         prev_fail_reason=str(prev_fail_str),\n",
    "#         date=date,\n",
    "#     )\n",
    "#     # print(formatted_prompt)\n",
    "#     query=json.loads(llm_engine.complete(formatted_prompt).text.strip())['query']\n",
    "    \n",
    "#     print(\"query generated\")\n",
    "#     print(query)\n",
    "    \n",
    "#     for attempt in range(retry):\n",
    "#         try:\n",
    "#             with engine.connect() as conn:\n",
    "#                 # Safety check\n",
    "#                 if any(keyword in query.upper() for keyword in [\" DROP \", \"DELETE\", \"UPDATE\", \"INSERT\"]):\n",
    "#                     raise ValueError(\"Modification queries are blocked\")\n",
    "                \n",
    "#                 # Execute and fetch results\n",
    "#                 cursor = conn.execute(text(query))\n",
    "#                 results = cursor.fetchall()\n",
    "#                 print(results)\n",
    "#                 return {\n",
    "#                     \"query\": query,\n",
    "#                     \"results\": results,\n",
    "#                     \"error\": None,\n",
    "#                     \"question\": question\n",
    "#                 }\n",
    "#         except (SQLAlchemyError, ValueError) as e:\n",
    "#             print(f\"retrying {type(e).__name__}: {str(e)}\")\n",
    "#             error_msg = f\"{type(e).__name__}: {str(e)}\"\n",
    "#             prev_sql_list.append(query)\n",
    "#             prev_fail_reason.append(error_msg)\n",
    "            \n",
    "#             # Regenerate prompt with updated attempts\n",
    "#             prev_sql_str = \"\\n- \".join(prev_sql_list)\n",
    "#             prev_fail_str = \"\\n- \".join(prev_fail_reason)\n",
    "#             formatted_prompt = sql_prompt.format(\n",
    "#                 question=question,\n",
    "#                 schema=schema,\n",
    "#                 domain_knowledge=domain_knowledge,\n",
    "#                 prev_sql_list=prev_sql_str,\n",
    "#                 prev_fail_reason=prev_fail_str,\n",
    "#                 date=date,\n",
    "#             )\n",
    "#             # Regenerate query\n",
    "#             try:\n",
    "#                 response = llm_engine.complete(formatted_prompt).text.strip()\n",
    "#                 print(response)\n",
    "#                 query = json.loads(response)['query']\n",
    "#             except (json.JSONDecodeError, KeyError) as e:\n",
    "#                 continue\n",
    "    \n",
    "#     return {\"error\": f\"Failed after {retry} retries\"}\n",
    "    \n",
    "\n",
    "\n",
    "# result = generate_sql_query(\n",
    "#     llm=llm_openai_o3_200k,\n",
    "#     engine=engine,\n",
    "#     question=\"Downtime on equipments in last 24 hours\",\n",
    "#     schema=database_schema,\n",
    "#     domain_knowledge=domain_knowledge,\n",
    "#     prev_sql_list=[],  # From previous attempts\n",
    "#     prev_fail_reason=[]  # Previous errors\n",
    "# )\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "import json\n",
    "\n",
    "# def final_ans(llm, question: str, domain_knowledge: str, result: str, sql_query:str,data_schema:str, chunk_size: int = 200000):\n",
    "#     \"\"\"\n",
    "#     Generates a final LLM output by interpreting the SQL result table in chunks.\n",
    "#     It does not perform any calculations but provides context and insights.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     interpretation_prompt = PromptTemplate(\"\"\"\n",
    "#     Role: Data Analyst specializing in industrial equipment systems.\n",
    "\n",
    "#     Task: Interpret the given SQL result table based on domain-specific knowledge.\n",
    "    \n",
    "#     **Context:**\n",
    "#     - Industry-specific knowledge: {domain_knowledge}\n",
    "#     - User question: {question}\n",
    "#     - database Schema :{data_schema}\n",
    "#     - SQL query : {sql_query}\n",
    "#     - SQL query result table:\n",
    "#     ```\n",
    "#     {result_chunk}\n",
    "#     ```\n",
    "\n",
    "#     **Response Guidelines:**\n",
    "#     - Summarize the key insights from the result.\n",
    "#     - Do NOT perform any calculations or draw conclusions.\n",
    "#     - Present observations neutrally, allowing the user to decide further actions.\n",
    "#     - Maintain clarity and conciseness.\n",
    "#     - Do not give wage ans make sure the unit is right\n",
    "\n",
    "#     Response:\n",
    "#     \"\"\")\n",
    "    \n",
    "#     responses = []\n",
    "    \n",
    "#     for i in range(0, len(result), chunk_size):\n",
    "#         chunk = result[i:i+chunk_size]\n",
    "#         formatted_prompt = interpretation_prompt.format(\n",
    "#             question=question,\n",
    "#             domain_knowledge=domain_knowledge,\n",
    "#             result_chunk=chunk,\n",
    "#             data_schema=data_schema,\n",
    "#             sql_query=sql_query\n",
    "#         )\n",
    "#         response = llm.complete(formatted_prompt).text.strip()\n",
    "#         responses.append(response)\n",
    "#         print(\"intermediate response\")\n",
    "#         print(response)\n",
    "    \n",
    "#     consolidated_prompt = PromptTemplate(\"\"\"\n",
    "#     Role: Data Analyst specializing in industrial equipment systems.\n",
    "\n",
    "#     Task: Summarize the insights from multiple interpretations of the SQL result table.\n",
    "    \n",
    "#     **Context:**\n",
    "#     - Industry-specific knowledge: {domain_knowledge}\n",
    "#     - User question: {question}\n",
    "#     - Extracted insights from chunks:\n",
    "#     ```\n",
    "#     {final_response}\n",
    "#     ```\n",
    "\n",
    "#     **Response Guidelines:**\n",
    "#     - Provide a clear and structured summary of the insights.\n",
    "#     - Do NOT perform any calculations or draw conclusions.\n",
    "#     - Present observations neutrally, allowing the user to decide further actions.\n",
    "#     - Maintain clarity and conciseness.\n",
    "#     - Do not give wage ans make sure the unit is right\n",
    "\n",
    "#     Response:\n",
    "#     \"\"\")\n",
    "    \n",
    "#     final_response = \"\\n\".join(responses)\n",
    "#     formatted_consolidated_prompt = consolidated_prompt.format(\n",
    "#         question=question,\n",
    "#         domain_knowledge=domain_knowledge,\n",
    "#         final_response=final_response\n",
    "#     )\n",
    "    \n",
    "#     consolidated_response = llm.complete(formatted_consolidated_prompt).text.strip()\n",
    "    \n",
    "#     return consolidated_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_ans(llm_openai_o3_200k,question,domain_knowledge,str(result['results']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final agent flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step get_question\n",
      "Step get_question produced event CustomInputQuestion\n",
      "How is Fermentation doing, % ethanol, % total sugars, % lactic acid, % acetic acid, pH and temperature in last batch\n",
      "Running step validate_question\n",
      "question : How is Fermentation doing, % ethanol, % total sugars, % lactic acid, % acetic acid, pH and temperature in last batch\n",
      "<class 'bool'> True\n",
      "Enough data to create sql query\n",
      "Step validate_question produced event GenerateQueryWithRetry\n",
      "##########################################3\n",
      "\n",
      "##########################################3\n",
      "The question contains enough details to generate a response.\n",
      "##########################################3\n",
      "Assumption We assume that the fermentation performance metrics are recorded in the HPLC_Data table. In particular, we use '% Ethanol (w/v)', '% Total Sugars (w/v)', '% Lactic Acid (w/v)', '% Acetic Acid (w/v)', 'pH', and 'Prop Temp (F)' as the key columns. Furthermore, we assume that the “last batch” can be determined by selecting the row with the most recent 'Drop Date and Time'. No additional joins (with fermentation_data or DE tables) are needed since the required fermentation parameters are captured in HPLC_Data.\n",
      "Running step Generate_Final_Ans\n",
      "query generated\n",
      "SELECT batch_number, ethanol, total_sugars, lactic_acid, acetic_acid, ph, temp FROM fermentation_data ORDER BY id DESC LIMIT 1;\n",
      "[('9112', '', '', '', '', '', '')]\n",
      "[('9112', '', '', '', '', '', '')]\n",
      "intermediate response\n",
      "Based on the SQL query result for the most recent batch (#9112), I observe that:\n",
      "\n",
      "1. The data fields for key fermentation parameters are empty:\n",
      "- Ethanol %\n",
      "- Total Sugars %\n",
      "- Lactic Acid %\n",
      "- Acetic Acid %\n",
      "- pH\n",
      "- Temperature\n",
      "\n",
      "This appears to be missing or incomplete data for the latest fermentation batch. Without these values, I cannot provide any specific insights about the fermentation performance metrics you asked about.\n",
      "\n",
      "To get meaningful information about the fermentation performance, you may want to:\n",
      "1. Check if there are data entry issues\n",
      "2. Look at previous batch records\n",
      "3. Verify if the batch has completed sampling/testing\n",
      "\n",
      "Would you like to query data from a different batch or timeframe to get the information you're seeking?\n",
      "Step Generate_Final_Ans produced event StopEvent\n",
      "##########################################3\n",
      "Query : SELECT batch_number, ethanol, total_sugars, lactic_acid, acetic_acid, ph, temp FROM fermentation_data ORDER BY id DESC LIMIT 1;\n",
      "##########################################3\n",
      "Result : [('9112', '', '', '', '', '', '')]\n",
      "Summary of Findings:\n",
      "\n",
      "1. Data Availability Issue\n",
      "- Batch #9112 (most recent) shows no recorded values for:\n",
      "  * Ethanol percentage\n",
      "  * Total Sugars percentage\n",
      "  * Lactic Acid percentage\n",
      "  * Acetic Acid percentage\n",
      "  * pH level\n",
      "  * Temperature reading\n",
      "\n",
      "2. Data Quality Observations\n",
      "- Complete data absence across all key fermentation parameters\n",
      "- No partial data available for any of the requested metrics\n",
      "- Unable to assess fermentation performance due to missing values\n",
      "\n",
      "3. Potential Next Steps for Consideration\n",
      "- Data from previous batches may be available for review\n",
      "- Current batch may require completion of sampling/testing\n",
      "- System data entry verification may be needed\n",
      "\n",
      "Note: Given the complete absence of data, no performance assessment or comparison against standard operating parameters can be made at this time. Would you like to examine data from earlier batches?\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    InputRequiredEvent,\n",
    "    HumanResponseEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    StopEvent,\n",
    "    StartEvent,\n",
    "    Context,\n",
    "    Event\n",
    ")\n",
    "\n",
    "# Define custom events with proper typing\n",
    "class ValidatedQuestionEvent(HumanResponseEvent):\n",
    "    pass\n",
    "\n",
    "# Remove the instruction field if not needed, or make it optional\n",
    "class CustomInputQuestion(InputRequiredEvent):\n",
    "    # Inherits prefix: str from InputRequiredEvent\n",
    "    pass  # Removed instruction field since it's not used\n",
    "\n",
    "class AdditionlInfo(InputRequiredEvent):\n",
    "    pass\n",
    "\n",
    "class RephraseQuestion(HumanResponseEvent):\n",
    "    pass\n",
    "\n",
    "class GenerateQueryWithRetry(Event):\n",
    "    pass \n",
    "\n",
    "class ProgressEvent(Event):\n",
    "    msg: str\n",
    "\n",
    "class question_validate_wf(Workflow):\n",
    "    def __init__(self, llm1,llm2,llm3, schema, domain_knowledge,engine,debug=True):\n",
    "        # Remove the self.ctx.set() call from here\n",
    "        super().__init__(timeout=300, verbose=True)\n",
    "        self.llm1 = llm1\n",
    "        self.llm2 = llm2\n",
    "        self.llm3= llm3\n",
    "        self.schema = schema\n",
    "        self.domain_knowledge = domain_knowledge\n",
    "        self.debug=debug\n",
    "        self.engine=engine\n",
    "    @step\n",
    "    async def get_question(self, ev: StartEvent) -> CustomInputQuestion:\n",
    "        return CustomInputQuestion(prefix=\"Enter your question: \")  # Now valid\n",
    "    \n",
    "    @step\n",
    "    async def validate_question(self,ctx: Context, ev: ValidatedQuestionEvent) -> GenerateQueryWithRetry|AdditionlInfo:\n",
    "        if self.debug:\n",
    "            print(\"question :\",ev.response)\n",
    "        await ctx.set(\"original_question\",ev.response)\n",
    "        # print(\"schema :\",self.schema)\n",
    "        # print(\"domain :\",self.domain_knowledge)\n",
    "        response_json=check_sql_feasibility(self.llm1, question=ev.response, schema=self.schema, domain_knowledge=self.domain_knowledge)\n",
    "        print(type(response_json[\"sufficient\"]),response_json[\"sufficient\"])\n",
    "        await ctx.set(\"sufficient\",response_json[\"sufficient\"])\n",
    "        await ctx.set(\"Assumption\",response_json[\"Assumption\"])\n",
    "        await ctx.set(\"Follow_up_Question\",response_json[\"question\"])\n",
    "        ctx.write_event_to_stream(ProgressEvent(msg=f\"\"))\n",
    "        if response_json[\"sufficient\"]:\n",
    "            if self.debug:\n",
    "                print(\"Enough data to create sql query\")\n",
    "            ctx.write_event_to_stream(ProgressEvent(msg=f\"The question contains enough details to generate a response.\"))\n",
    "            p_a=response_json[\"Assumption\"]\n",
    "            ctx.write_event_to_stream(ProgressEvent(msg=f\"Assumption {p_a}\"))\n",
    "            return GenerateQueryWithRetry()\n",
    "        else :\n",
    "            if self.debug:\n",
    "                print(\"Not enough data to create sql query follow up question\")\n",
    "            ctx.write_event_to_stream(ProgressEvent(msg=f\"The question lacks sufficient information to generate a response and requires a follow-up question.\"))\n",
    "            return AdditionlInfo(prefix=response_json[\"question\"])\n",
    "        \n",
    "    @step\n",
    "    async def handle_rephrase(self, ctx: Context,ev: RephraseQuestion) -> ValidatedQuestionEvent :\n",
    "        # if self.debug:\n",
    "        #     print(\"question :\",ev.response)\n",
    "        prev_question = await ctx.get(\"original_question\")\n",
    "        prev_feedback = await ctx.get(\"Follow_up_Question\")\n",
    "        \n",
    "        rephrase_que = json.loads(handle_rephrase_helper(\n",
    "            llm=self.llm2,\n",
    "            prev_question=prev_question,\n",
    "            prev_feedback=prev_feedback,\n",
    "            response=ev.response,\n",
    "        ))\n",
    "        if self.debug:\n",
    "            print(\"rephrased question :\",rephrase_que['question'])\n",
    "        ctx.write_event_to_stream(ProgressEvent(msg=f\"Rephrased question : {rephrase_que['question']}\"))\n",
    "        return ValidatedQuestionEvent(response=rephrase_que['question'])\n",
    "    \n",
    "    @step\n",
    "    async def Generate_Final_Ans(self, ctx: Context,ev:GenerateQueryWithRetry) -> StopEvent:\n",
    "        sql_prompt = PromptTemplate(\"\"\"\\\n",
    "        Role: Expert SQL Engineer specializing in industrial equipment systems\n",
    "\n",
    "        Task: Generate accurate SQL query following this workflow:\n",
    "\n",
    "        1. **Schema Analysis**:\n",
    "        - Identify required tables and its column and Use first row data to understand column meanings: {schema}\n",
    "        - Establish table relationships using foreign keys\n",
    "\n",
    "        2. **Domain Validation**:\n",
    "        - Cross-check with industry specific knowledge:\n",
    "        {domain_knowledge}\n",
    "\n",
    "\n",
    "        3. Error Avoidance:\n",
    "        - Previous failed queries: {prev_sql_list}\n",
    "        - Failure reasons: {prev_fail_reason}\n",
    "        - Actively avoid repeating these patterns\n",
    "\n",
    "        4. Temporal Context:\n",
    "        - Current system datetime: {date}\n",
    "\n",
    "        **Query Requirements**:\n",
    "        - Use only tables in the schema\n",
    "        - Prioritize index-friendly operations\n",
    "        - Include necessary JOINs but avoid Cartesian products\n",
    "        - Handle NULL values appropriately\n",
    "\n",
    "        Current Task:\n",
    "        Question: {question}\n",
    "\n",
    "        Response Rules:\n",
    "        - Return **ONLY valid JSON** with the following structure:\n",
    "        {{\n",
    "        \"query\": \"SELECT...\",\n",
    "        \"rationale\": \"Brief technical justification\"\n",
    "        }}\n",
    "\n",
    "        \"\"\")\n",
    "\n",
    "        def generate_sql_query(\n",
    "            llm_engine,\n",
    "            engine,\n",
    "            question: str,\n",
    "            schema: str,\n",
    "            domain_knowledge: str,\n",
    "            prev_sql_list: Optional[List[str]] = None,\n",
    "            prev_fail_reason: Optional[List[str]] = None,\n",
    "            date: str = datetime.datetime.now(),\n",
    "            retry:int=4\n",
    "        ) -> dict:\n",
    "            \"\"\"\n",
    "            Generates SQL query using industrial equipment database schema\n",
    "            \"\"\"\n",
    "            # Format previous attempts for prompt\n",
    "            prev_sql_str = \"\\n- \".join(prev_sql_list) if prev_sql_list else \"None\"\n",
    "            prev_fail_str = \"\\n- \".join(prev_fail_reason) if prev_fail_reason else \"None\"\n",
    "\n",
    "            formatted_prompt = sql_prompt.format(\n",
    "                question=question,\n",
    "                schema=schema,\n",
    "                domain_knowledge=domain_knowledge,\n",
    "                prev_sql_list=str(prev_sql_str),\n",
    "                prev_fail_reason=str(prev_fail_str),\n",
    "                date=date,\n",
    "            )\n",
    "            # print(formatted_prompt)\n",
    "            query=json.loads(llm_engine.complete(formatted_prompt).text.strip())['query']\n",
    "            \n",
    "            print(\"query generated\")\n",
    "            print(query)\n",
    "            \n",
    "            \n",
    "            for attempt in range(retry):\n",
    "                try:\n",
    "                    with engine.connect() as conn:\n",
    "                        # Safety check\n",
    "                        if any(keyword in query.upper() for keyword in [\" DROP \", \"DELETE\", \"UPDATE\", \"INSERT\"]):\n",
    "                            raise ValueError(\"Modification queries are blocked\")\n",
    "                        \n",
    "                        # Execute and fetch results\n",
    "                        cursor = conn.execute(text(query))\n",
    "                        results = cursor.fetchall()\n",
    "                        ctx.write_event_to_stream(ProgressEvent(msg=f\"Query : {query}\"))\n",
    "                        ctx.write_event_to_stream(ProgressEvent(msg=f\"Result : {results}\"))\n",
    "                        print(results)\n",
    "                        return {\n",
    "                            \"query\": query,\n",
    "                            \"results\": results,\n",
    "                            \"error\": None,\n",
    "                            \"question\": question\n",
    "                        }\n",
    "                except (SQLAlchemyError, ValueError) as e:\n",
    "                    print(f\"retrying {type(e).__name__}: {str(e)}\")\n",
    "                    error_msg = f\"{type(e).__name__}: {str(e)}\"\n",
    "                    prev_sql_list.append(query)\n",
    "                    prev_fail_reason.append(error_msg)\n",
    "                    \n",
    "                    # Regenerate prompt with updated attempts\n",
    "                    prev_sql_str = \"\\n- \".join(prev_sql_list)\n",
    "                    prev_fail_str = \"\\n- \".join(prev_fail_reason)\n",
    "                    formatted_prompt = sql_prompt.format(\n",
    "                        question=question,\n",
    "                        schema=schema,\n",
    "                        domain_knowledge=domain_knowledge,\n",
    "                        prev_sql_list=prev_sql_str,\n",
    "                        prev_fail_reason=prev_fail_str,\n",
    "                        date=date,\n",
    "                    )\n",
    "                    # Regenerate query\n",
    "                    try:\n",
    "                        response = llm_engine.complete(formatted_prompt).text.strip()\n",
    "                        print(response)\n",
    "                        query = json.loads(response)['query']\n",
    "                    except (json.JSONDecodeError, KeyError) as e:\n",
    "                        continue\n",
    "            \n",
    "            return {\"error\": f\"Failed after {retry} retries\"}\n",
    "        result_sql_query = generate_sql_query(\n",
    "            llm_engine=self.llm1,\n",
    "            engine=engine,\n",
    "            question= await ctx.get(\"original_question\"),\n",
    "            schema=self.schema,\n",
    "            domain_knowledge=self.domain_knowledge,\n",
    "            prev_sql_list=[],  # From previous attempts\n",
    "            prev_fail_reason=[],  # Previous errors\n",
    "        )\n",
    "        print(result_sql_query['results'])\n",
    "        \n",
    "        def final_ans(llm, question: str, domain_knowledge: str, result: str, sql_query:str,data_schema:str, chunk_size: int = 200000):\n",
    "            \"\"\"\n",
    "            Generates a final LLM output by interpreting the SQL result table in chunks.\n",
    "            It does not perform any calculations but provides context and insights.\n",
    "            \"\"\"\n",
    "            \n",
    "            interpretation_prompt = PromptTemplate(\"\"\"\n",
    "            Role: Data Analyst specializing in industrial equipment systems.\n",
    "\n",
    "            Task: Interpret the given SQL result table based on domain-specific knowledge.\n",
    "            \n",
    "            **Context:**\n",
    "            - Industry-specific knowledge: {domain_knowledge}\n",
    "            - User question: {question}\n",
    "            - database Schema :{data_schema}\n",
    "            - SQL query : {sql_query}\n",
    "            - SQL query result table:\n",
    "            ```\n",
    "            {result_chunk}\n",
    "            ```\n",
    "\n",
    "            **Response Guidelines:**\n",
    "            - Summarize the key insights from the result.\n",
    "            - Do NOT perform any calculations or draw conclusions.\n",
    "            - Present observations neutrally, allowing the user to decide further actions.\n",
    "            - Maintain clarity and conciseness.\n",
    "            - Do not give wage ans make sure the unit is right\n",
    "            - if greeting question reply with just greeting\n",
    "\n",
    "            Response:\n",
    "            \"\"\")\n",
    "            \n",
    "            responses = []\n",
    "            \n",
    "            for i in range(0, len(result), chunk_size):\n",
    "                chunk = result[i:i+chunk_size]\n",
    "                formatted_prompt = interpretation_prompt.format(\n",
    "                    question=question,\n",
    "                    domain_knowledge=domain_knowledge,\n",
    "                    result_chunk=chunk,\n",
    "                    data_schema=data_schema,\n",
    "                    sql_query=sql_query\n",
    "                )\n",
    "                response = llm.complete(formatted_prompt).text.strip()\n",
    "                responses.append(response)\n",
    "                ctx.write_event_to_stream(ProgressEvent(msg=f\"intermediate Summary : {response}\"))\n",
    "                print(\"intermediate response\")\n",
    "                print(response)\n",
    "            \n",
    "            consolidated_prompt = PromptTemplate(\"\"\"\n",
    "            Role: Data Analyst specializing in industrial equipment systems.\n",
    "\n",
    "            Task: Summarize the insights from multiple interpretations of the SQL result table.\n",
    "            \n",
    "            **Context:**\n",
    "            - Industry-specific knowledge: {domain_knowledge}\n",
    "            - User question: {question}\n",
    "            - Extracted insights from chunks:\n",
    "            ```\n",
    "            {final_response}\n",
    "            ```\n",
    "\n",
    "            **Response Guidelines:**\n",
    "            - Provide a clear and structured summary of the insights.\n",
    "            - Do NOT perform any calculations or draw conclusions.\n",
    "            - Present observations neutrally, allowing the user to decide further actions.\n",
    "            - Maintain clarity and conciseness.\n",
    "            - Do not give wage ans make sure the unit is right\n",
    "            - if greeting question reply with just greeting\n",
    "\n",
    "            Response:\n",
    "            \"\"\")\n",
    "            \n",
    "            final_response = \"\\n\".join(responses)\n",
    "            formatted_consolidated_prompt = consolidated_prompt.format(\n",
    "                question=question,\n",
    "                domain_knowledge=domain_knowledge,\n",
    "                final_response=final_response\n",
    "            )\n",
    "            ctx.write_event_to_stream(ProgressEvent(msg=f\"Final Summary\"))\n",
    "            consolidated_response = llm.complete(formatted_consolidated_prompt).text.strip()\n",
    "            \n",
    "            return consolidated_response\n",
    "        conclusion=final_ans(self.llm3,await ctx.get(\"original_question\"),self.domain_knowledge,str(result_sql_query['results']),sql_query=result_sql_query['query'],data_schema=self.schema)\n",
    "        return StopEvent(conclusion)\n",
    "        \n",
    "        \n",
    "\n",
    "# Execution\n",
    "workflow = question_validate_wf(llm_openai_o3_200k,llm_mistral_large_32k,llm_claude_3_5_200k, database_schema, domain_knowledge,engine)\n",
    "handler = workflow.run()\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, CustomInputQuestion):\n",
    "        response = input(event.prefix)\n",
    "        print(response)\n",
    "        # feedback = {\"valid\": True, \"message\": \"Valid question\"}\n",
    "        \n",
    "        handler.ctx.send_event(\n",
    "            ValidatedQuestionEvent(\n",
    "                response=response,\n",
    "            )\n",
    "        )\n",
    "    elif isinstance(event, AdditionlInfo):\n",
    "        response = input(event.prefix)\n",
    "        # feedback = {\"valid\": True, \"message\": \"Valid question\"}\n",
    "        \n",
    "        handler.ctx.send_event(\n",
    "            RephraseQuestion(\n",
    "                response=response,\n",
    "            )\n",
    "        )\n",
    "    if isinstance(event, ProgressEvent):\n",
    "        # print(\"##########################################\")\n",
    "        # print(event.msg)\n",
    "        pass\n",
    "\n",
    "final_result = await handler\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "<class 'NoneType'>\n",
      "<class '__main__.CustomInputQuestion'>\n",
      "<class '__main__.ValidatedQuestionEvent'>\n",
      "<class '__main__.GenerateQueryWithRetry'>\n",
      "<class '__main__.AdditionlInfo'>\n",
      "Fact_finder_workflow.html\n"
     ]
    }
   ],
   "source": [
    "# view the flow chart \n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "draw_all_possible_flows(workflow, filename=\"Fact_finder_workflow.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (691651125.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[249], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    How is Fermentation doing, % ethanol, % total sugars, % lactic acid, % acetic acid, pH and temperature in last batch\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# sample question\n",
    "# How is Fermentation doing, % ethanol, % total sugars, % lactic acid, % acetic acid, pH and temperature in last batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_do add voting algo to generate multi sql_query and based on just one row output decide which one is the most optimal  in parallel and generate the voting for best\n",
    "# update the current rules function based on the interaction and feedback  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

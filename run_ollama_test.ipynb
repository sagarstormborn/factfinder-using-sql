{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# Initialize the first model\n",
    "llm1 = Ollama(model=\"qwen2.5:72b\", request_timeout=120.0)\n",
    "\n",
    "# Initialize the second model\n",
    "llm2 = Ollama(model=\"deepseek-r1:70b\", request_timeout=120.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_models(prompt):\n",
    "    # Query the first model\n",
    "    response1 = llm1.complete(prompt)\n",
    "\n",
    "    # Query the second model\n",
    "    response2 = llm2.complete(prompt)\n",
    "\n",
    "    return response1, response2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Translate the following English text to French: 'Hello, how are you?'\"\n",
    "response1, response2 = query_models(prompt)\n",
    "\n",
    "print(\"Response from Model 1:\", response1)\n",
    "print(\"Response from Model 2:\", response2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# Initialize the first model\n",
    "llm1 = Ollama(model=\"qwen2.5:72b\", request_timeout=120.0)\n",
    "llm2 = Ollama(model=\"llama3.3:latest\", request_timeout=120.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import BaseTool, FunctionTool\n",
    "_memory = \"user name is abc\"\n",
    "\n",
    "def current_memory_function() -> str:\n",
    "    \"\"\"Returns the current global memory string.\n",
    "    \n",
    "    Returns:\n",
    "        str: The accumulated memory string (editable globally), \n",
    "             initially empty\n",
    "    \"\"\"\n",
    "    return _memory\n",
    "current_memory_function_tool = FunctionTool.from_defaults(fn=current_memory_function)\n",
    "\n",
    "def update_memory(new_info: str) -> None:\n",
    "    \"\"\"Updates the global memory with new information if not already present.\n",
    "    \n",
    "    Args:\n",
    "        new_info (str): The string to add to memory if it contains \n",
    "                        previously unknown information\n",
    "    \"\"\"\n",
    "    global _memory\n",
    "    entries = _memory.split('\\n') if _memory else []\n",
    "    \n",
    "    # Add only if new information not in existing memory\n",
    "    if new_info.strip() and new_info not in entries:\n",
    "        entries.append(new_info)\n",
    "        _memory = '\\n'.join(entries)\n",
    "update_memory_tool = FunctionTool.from_defaults(fn=update_memory)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "agent = ReActAgent.from_tools([current_memory_function_tool, update_memory_tool], llm=llm1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\"What do u know so far\")\n",
    "print(response)\n",
    "response = agent.chat(\"i want to teach you something , i love to be happy\")\n",
    "print(response)\n",
    "response = agent.chat(\"i love sushi\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\"What do u know so far\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sql engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SQLDatabase\n",
    "from sqlalchemy import create_engine\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "# Configuration for the database\n",
    "@dataclass\n",
    "class Config:\n",
    "    DB_HOST: str = \"143.198.230.83\"\n",
    "    DB_PORT: int = 3306\n",
    "    DB_NAME: str = \"golgixportal\"\n",
    "    DB_USER: str = \"golgix\"\n",
    "    DB_PASSWORD: str = \"preciseV5\"\n",
    "    ALLOWED_TABLES: list[str] = field(default_factory=lambda: [\n",
    "        \"DE\",\n",
    "        \"HPLC_Data\",\n",
    "        \"fermentation_data\",\n",
    "        \"plc_data_1\",\n",
    "        \"plc_data_2\",\n",
    "        \"plc_data_3\",\n",
    "        \"plc_data_4\"\n",
    "    ])\n",
    "\n",
    "# Load configuration\n",
    "config = Config()\n",
    "\n",
    "# Setup the SQLAlchemy engine URI\n",
    "db_uri = f\"mysql+pymysql://{config.DB_USER}:{config.DB_PASSWORD}@{config.DB_HOST}:{config.DB_PORT}/{config.DB_NAME}\"\n",
    "\n",
    "# Initialize the SQLDatabase with the URI and include_tables parameter\n",
    "sql_database = SQLDatabase.from_uri(db_uri, include_tables=config.ALLOWED_TABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# Initialize the first model\n",
    "llm1 = Ollama(model=\"qwen2.5:72b\", request_timeout=120.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import QueryPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagar/anaconda3/envs/factfinder/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "ðŸ“– For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "# setup Arize Phoenix for logging/observability\n",
    "import phoenix as px\n",
    "import llama_index.core\n",
    "\n",
    "px.launch_app()\n",
    "llama_index.core.set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "sql_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    llm=llm1,\n",
    "    embed_model='local',\n",
    "    # tables=[\"albums\", \"tracks\", \"artists\"],\n",
    "    verbose=True,\n",
    "\n",
    ")\n",
    "sql_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=sql_query_engine,\n",
    "    name=\"sql_tool\",\n",
    "    description=(\n",
    "        \"Useful for translating a natural language query into a SQL query\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import QueryPipeline as QP\n",
    "\n",
    "qp = QP(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.react.types import (\n",
    "    ActionReasoningStep,\n",
    "    ObservationReasoningStep,\n",
    "    ResponseReasoningStep,\n",
    ")\n",
    "from llama_index.core.agent import Task, AgentChatResponse\n",
    "from llama_index.core.query_pipeline import (\n",
    "    StatefulFnComponent,\n",
    "    QueryComponent,\n",
    "    ToolRunnerComponent,\n",
    ")\n",
    "from llama_index.core.llms import MessageRole\n",
    "from typing import Dict, Any, Optional, Tuple, List, cast\n",
    "\n",
    "\n",
    "# Input Component\n",
    "## This is the component that produces agent inputs to the rest of the components\n",
    "## Can also put initialization logic here.\n",
    "def agent_input_fn(state: Dict[str, Any]) -> str:\n",
    "    \"\"\"Agent input function.\n",
    "\n",
    "    Returns:\n",
    "        A Dictionary of output keys and values. If you are specifying\n",
    "        src_key when defining links between this component and other\n",
    "        components, make sure the src_key matches the specified output_key.\n",
    "\n",
    "    \"\"\"\n",
    "    task = state[\"task\"]\n",
    "    if len(state[\"current_reasoning\"]) == 0:\n",
    "        reasoning_step = ObservationReasoningStep(observation=task.input)\n",
    "        state[\"current_reasoning\"].append(reasoning_step)\n",
    "    return task.input\n",
    "\n",
    "\n",
    "agent_input_component = StatefulFnComponent(fn=agent_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActChatFormatter\n",
    "from llama_index.core.query_pipeline import InputComponent, Link\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import BaseTool\n",
    "\n",
    "\n",
    "## define prompt function\n",
    "def react_prompt_fn(\n",
    "    state: Dict[str, Any], input: str, tools: List[BaseTool]\n",
    ") -> List[ChatMessage]:\n",
    "    task = state[\"task\"]\n",
    "    # Add input to reasoning\n",
    "    chat_formatter = ReActChatFormatter()\n",
    "    cur_prompt = chat_formatter.format(\n",
    "        tools,\n",
    "        chat_history=task.memory.get(),\n",
    "        current_reasoning=state[\"current_reasoning\"],\n",
    "    )\n",
    "    return cur_prompt\n",
    "\n",
    "\n",
    "react_prompt_component = StatefulFnComponent(\n",
    "    fn=react_prompt_fn, partial_dict={\"tools\": [sql_tool]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set, Optional\n",
    "from llama_index.core.agent.react.output_parser import ReActOutputParser\n",
    "from llama_index.core.llms import ChatResponse\n",
    "from llama_index.core.agent.types import Task\n",
    "\n",
    "\n",
    "def parse_react_output_fn(state: Dict[str, Any], chat_response: ChatResponse):\n",
    "    \"\"\"Parse ReAct output into a reasoning step.\"\"\"\n",
    "    output_parser = ReActOutputParser()\n",
    "    reasoning_step = output_parser.parse(chat_response.message.content)\n",
    "    return {\"done\": reasoning_step.is_done, \"reasoning_step\": reasoning_step}\n",
    "\n",
    "\n",
    "parse_react_output = StatefulFnComponent(fn=parse_react_output_fn)\n",
    "\n",
    "\n",
    "def run_tool_fn(state: Dict[str, Any], reasoning_step: ActionReasoningStep):\n",
    "    \"\"\"Run tool and process tool output.\"\"\"\n",
    "    task = state[\"task\"]\n",
    "    tool_runner_component = ToolRunnerComponent(\n",
    "        [sql_tool], callback_manager=task.callback_manager\n",
    "    )\n",
    "    tool_output = tool_runner_component.run_component(\n",
    "        tool_name=reasoning_step.action,\n",
    "        tool_input=reasoning_step.action_input,\n",
    "    )\n",
    "    observation_step = ObservationReasoningStep(observation=str(tool_output))\n",
    "    state[\"current_reasoning\"].append(observation_step)\n",
    "    # TODO: get output\n",
    "\n",
    "    # return tuple of current output and False for is_done\n",
    "    return observation_step.get_content(), False\n",
    "\n",
    "\n",
    "run_tool = StatefulFnComponent(fn=run_tool_fn)\n",
    "\n",
    "\n",
    "def process_response_fn(\n",
    "    state: Dict[str, Any], response_step: ResponseReasoningStep\n",
    "):\n",
    "    \"\"\"Process response.\"\"\"\n",
    "    state[\"current_reasoning\"].append(response_step)\n",
    "    return response_step.response, True\n",
    "\n",
    "\n",
    "process_response = StatefulFnComponent(fn=process_response_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import QueryPipeline as QP\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "qp.add_modules(\n",
    "    {\n",
    "        \"agent_input\": agent_input_component,\n",
    "        \"react_prompt\": react_prompt_component,\n",
    "        \"llm\": llm1,\n",
    "        \"react_output_parser\": parse_react_output,\n",
    "        \"run_tool\": run_tool,\n",
    "        \"process_response\": process_response,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link input to react prompt to parsed out response (either tool action/input or observation)\n",
    "qp.add_chain([\"agent_input\", \"react_prompt\", \"llm\", \"react_output_parser\"])\n",
    "\n",
    "# add conditional link from react output to tool call (if not done)\n",
    "qp.add_link(\n",
    "    \"react_output_parser\",\n",
    "    \"run_tool\",\n",
    "    condition_fn=lambda x: not x[\"done\"],\n",
    "    input_fn=lambda x: x[\"reasoning_step\"],\n",
    ")\n",
    "# add conditional link from react output to final response processing (if done)\n",
    "qp.add_link(\n",
    "    \"react_output_parser\",\n",
    "    \"process_response\",\n",
    "    condition_fn=lambda x: x[\"done\"],\n",
    "    input_fn=lambda x: x[\"reasoning_step\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_dag.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"agent_dag.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x79cd634ee070>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(qp.clean_dag)\n",
    "net.show(\"agent_dag.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FnAgentWorker\n",
    "from typing import Dict, Tuple, Any\n",
    "\n",
    "\n",
    "def run_agent_fn(state: Dict[str, Any]) -> Tuple[Dict[str, Any], bool]:\n",
    "    \"\"\"Run agent function.\"\"\"\n",
    "    task, qp = state[\"__task__\"], state[\"query_pipeline\"]\n",
    "    # if first run, then set query pipeline state to initial variables\n",
    "    if state[\"is_first\"]:\n",
    "        qp.set_state(\n",
    "            {\n",
    "                \"task\": task,\n",
    "                \"current_reasoning\": [],\n",
    "            }\n",
    "        )\n",
    "        state[\"is_first\"] = False\n",
    "\n",
    "    # no explicit input here, just run root node\n",
    "    response_str, is_done = qp.run()\n",
    "    # if done, store output and log to memory\n",
    "    # a core memory module is available in the `task` variable. Of course you can log\n",
    "    # and store your own memory as well\n",
    "    state[\"__output__\"] = response_str\n",
    "    if is_done:\n",
    "        task.memory.put_messages(\n",
    "            [\n",
    "                ChatMessage(content=task.input, role=MessageRole.USER),\n",
    "                ChatMessage(content=response_str, role=MessageRole.ASSISTANT),\n",
    "            ]\n",
    "        )\n",
    "    return state, is_done\n",
    "\n",
    "\n",
    "agent = FnAgentWorker(\n",
    "    fn=run_agent_fn,\n",
    "    initial_state={\"query_pipeline\": qp, \"is_first\": True},\n",
    ").as_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start task\n",
    "task = agent.create_task(\n",
    "    \"Downtime on equipment last 24 hours\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module agent_input with input: \n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module react_prompt with input: \n",
      "input: Downtime on equipment last 24 hours\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm with input: \n",
      "messages: [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='You are designed to help with a variety of tasks, from answering questions to providi...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module react_output_parser with input: \n",
      "chat_response: assistant: Thought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: In the last 24 hours, there has been no downtime on the equipment. The query did not retu...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module process_response with input: \n",
      "response_step: thought=\"I can answer without using any more tools. I'll use the user's language to answer.\" response='In the last 24 hours, there has been no downtime on the equipment. The query did not return any r...\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "step_output = agent.run_step(task.task_id)\n",
    "step_output = agent.run_step(task.task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_output.is_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the last 24 hours, there has been no downtime on the equipment. The query did not return any records where the flow rate (FI_3150_PV) was zero, indicating that the equipment has been operational throughout this period.\n"
     ]
    }
   ],
   "source": [
    "response = agent.finalize_response(task.task_id)\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Simple Retry Agent Pipeline for Text-to-SQL \n",
    "\n",
    "let's try a much simpler agent pipeline that only does text-to-SQL, with retry-logic.\n",
    "\n",
    "We try a simple text-based \"retry\" prompt where given the user input and previous conversation history, can generate a modified query that outputs the right result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# Initialize the first model\n",
    "llm1 = Ollama(model=\"qwen2.5:72b\", request_timeout=300.0)\n",
    "# llm1 = Ollama(model=\"qwen2.5:72b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SQLDatabase\n",
    "from sqlalchemy import create_engine\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "# Configuration for the database\n",
    "@dataclass\n",
    "class Config:\n",
    "    DB_HOST: str = \"143.198.230.83\"\n",
    "    DB_PORT: int = 3306\n",
    "    DB_NAME: str = \"golgixportal\"\n",
    "    DB_USER: str = \"golgix\"\n",
    "    DB_PASSWORD: str = \"preciseV5\"\n",
    "    ALLOWED_TABLES: list[str] = field(default_factory=lambda: [\n",
    "        \"DE\",\n",
    "        \"HPLC_Data\",\n",
    "        \"fermentation_data\",\n",
    "        \"plc_data_1\",\n",
    "        \"plc_data_2\",\n",
    "        \"plc_data_3\",\n",
    "        \"plc_data_4\"\n",
    "    ])\n",
    "\n",
    "# Load configuration\n",
    "config = Config()\n",
    "\n",
    "# Setup the SQLAlchemy engine URI\n",
    "db_uri = f\"mysql+pymysql://{config.DB_USER}:{config.DB_PASSWORD}@{config.DB_HOST}:{config.DB_PORT}/{config.DB_NAME}\"\n",
    "\n",
    "# Initialize the SQLDatabase with the URI and include_tables parameter\n",
    "sql_database = SQLDatabase.from_uri(db_uri, include_tables=config.ALLOWED_TABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "sql_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    llm=llm1,\n",
    "    embed_model='local',\n",
    "    # tables=[\"albums\", \"tracks\", \"artists\"],\n",
    "    verbose=True,\n",
    "\n",
    ")\n",
    "sql_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=sql_query_engine,\n",
    "    name=\"sql_tool\",\n",
    "    description=(\n",
    "        \"Useful for translating a natural language query into a SQL query\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import Task, AgentChatResponse\n",
    "from typing import Dict, Any\n",
    "from llama_index.core.query_pipeline import StatefulFnComponent\n",
    "\n",
    "\n",
    "def agent_input_fn(state: Dict[str, Any]) -> Dict:\n",
    "    \"\"\"Agent input function.\"\"\"\n",
    "    task = state[\"task\"]\n",
    "    state[\"convo_history\"].append(f\"User: {task.input}\")\n",
    "    convo_history_str = \"\\n\".join(state[\"convo_history\"]) or \"None\"\n",
    "    return {\"input\": task.input, \"convo_history\": convo_history_str}\n",
    "\n",
    "\n",
    "agent_input_component = StatefulFnComponent(fn=agent_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "retry_prompt_str = \"\"\"\\\n",
    "You are trying to generate a proper natural language query given a user input.\n",
    "\n",
    "This query will then be interpreted by a downstream text-to-SQL agent which\n",
    "will convert the query to a SQL statement. If the agent triggers an error,\n",
    "then that will be reflected in the current conversation history (see below).\n",
    "\n",
    "If the conversation history is None, use the user input. If its not None,\n",
    "generate a new SQL query that avoids the problems of the previous SQL query.\n",
    "\n",
    "Input: {input}\n",
    "Convo history (failed attempts): \n",
    "{convo_history}\n",
    "\n",
    "New input: \"\"\"\n",
    "retry_prompt = PromptTemplate(retry_prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Response\n",
    "from typing import Tuple\n",
    "\n",
    "validate_prompt_str = \"\"\"\\\n",
    "Given the user query, validate whether the inferred SQL query and response from executing the query is correct and answers the query.\n",
    "\n",
    "Answer with YES or NO.\n",
    "\n",
    "Query: {input}\n",
    "Inferred SQL query: {sql_query}\n",
    "SQL Response: {sql_response}\n",
    "\n",
    "Result: \"\"\"\n",
    "validate_prompt = PromptTemplate(validate_prompt_str)\n",
    "\n",
    "MAX_ITER = 5\n",
    "\n",
    "\n",
    "def agent_output_fn(\n",
    "    state: Dict[str, Any], output: Response\n",
    ") -> Tuple[AgentChatResponse, bool]:\n",
    "    \"\"\"Agent output component.\"\"\"\n",
    "    task = state[\"task\"]\n",
    "    print(f\"> Inferred SQL Query: {output.metadata['sql_query']}\")\n",
    "    print(f\"> SQL Response: {str(output)}\")\n",
    "    state[\"convo_history\"].append(\n",
    "        f\"Assistant (inferred SQL query): {output.metadata['sql_query']}\"\n",
    "    )\n",
    "    state[\"convo_history\"].append(f\"Assistant (response): {str(output)}\")\n",
    "\n",
    "    # run a mini chain to get response\n",
    "    validate_prompt_partial = validate_prompt.as_query_component(\n",
    "        partial={\n",
    "            \"sql_query\": output.metadata[\"sql_query\"],\n",
    "            \"sql_response\": str(output),\n",
    "        }\n",
    "    )\n",
    "    qp = QP(chain=[validate_prompt_partial, llm1])\n",
    "    validate_output = qp.run(input=task.input)\n",
    "\n",
    "    state[\"count\"] += 1\n",
    "    is_done = False\n",
    "    if state[\"count\"] >= MAX_ITER:\n",
    "        is_done = True\n",
    "    if \"YES\" in validate_output.message.content:\n",
    "        is_done = True\n",
    "\n",
    "    return str(output), is_done\n",
    "\n",
    "\n",
    "agent_output_component = StatefulFnComponent(fn=agent_output_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import (\n",
    "    QueryPipeline as QP,\n",
    "    Link,\n",
    "    InputComponent,\n",
    ")\n",
    "\n",
    "qp = QP(\n",
    "    modules={\n",
    "        \"input\": agent_input_component,\n",
    "        \"retry_prompt\": retry_prompt,\n",
    "        \"llm\": llm1,\n",
    "        \"sql_query_engine\": sql_query_engine,\n",
    "        \"output_component\": agent_output_component,\n",
    "    },\n",
    "    verbose=True,\n",
    ")\n",
    "qp.add_link(\n",
    "    \"input\", \"retry_prompt\", dest_key=\"input\", input_fn=lambda x: x[\"input\"]\n",
    ")\n",
    "qp.add_link(\n",
    "    \"input\",\n",
    "    \"retry_prompt\",\n",
    "    dest_key=\"convo_history\",\n",
    "    input_fn=lambda x: x[\"convo_history\"],\n",
    ")\n",
    "qp.add_chain([\"retry_prompt\", \"llm\", \"sql_query_engine\", \"output_component\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FnAgentWorker\n",
    "\n",
    "\n",
    "def run_agent_fn(state: Dict[str, Any]) -> Tuple[Dict[str, Any], bool]:\n",
    "    \"\"\"Run agent function.\"\"\"\n",
    "    task, qp = state[\"__task__\"], state[\"query_pipeline\"]\n",
    "    # if first run, then set query pipeline state to initial variables\n",
    "    if state[\"is_first\"]:\n",
    "        qp.set_state({\"task\": task, \"convo_history\": [], \"count\": 0})\n",
    "        state[\"is_first\"] = False\n",
    "\n",
    "    # run the pipeline, get response\n",
    "    response_str, is_done = qp.run()\n",
    "    if is_done:\n",
    "        state[\"__output__\"] = response_str\n",
    "    return state, is_done\n",
    "\n",
    "\n",
    "agent = FnAgentWorker(\n",
    "    fn=run_agent_fn,\n",
    "    initial_state={\"query_pipeline\": qp, \"is_first\": True},\n",
    ").as_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module retry_prompt with input: \n",
      "input: Downtime on equipment last 24 hours ?\n",
      "convo_history: User: Downtime on equipment last 24 hours ?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm with input: \n",
      "messages: You are trying to generate a proper natural language query given a user input.\n",
      "\n",
      "This query will then be interpreted by a downstream text-to-SQL agent which\n",
      "will convert the query to a SQL statement. I...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module sql_query_engine with input: \n",
      "input: assistant: Given the user's request and the conversation history, it seems like the initial attempt to generate a SQL query for \"Downtime on equipment last 24 hours\" might have failed. To refine the q...\n",
      "\n",
      "\u001b[0m> Table Info: Table 'DE' has columns: recordid (INTEGER), datetime (DATETIME), date (DATE), shift (VARCHAR(50)), operator (VARCHAR(50)), hour (VARCHAR(100)), category (VARCHAR(50)), parameter (VARCHAR(50)), target (VARCHAR(50)), entered_value (VARCHAR(50)), user (VARCHAR(50)), .\n",
      "> Table Info: Table 'HPLC_Data' has columns: Quarter (VARCHAR(10)), Ferm Drop Month (VARCHAR(20)), Ferm No (VARCHAR(10)), Batch No (VARCHAR(20)), Ferm Hour (VARCHAR(50)), Sample Description (VARCHAR(50)), Prop Mash % Solids (FLOAT), Prop Urea (lbs) (FLOAT), Prop Antibiotic (lbs) (FLOAT), Prop GA (gal) (FLOAT), Prop Protease (gal) (FLOAT), Ferm GA 1st Add. (gal) (FLOAT), Ferm GA 2nd Add (gal) (FLOAT), Ferm GA Flow (mL/min) (FLOAT), Ferm Fill Time (hrs) (FLOAT), GA Meter Add. (gal) (FLOAT), Total Ferm GA (gal) (FLOAT), Ferm AA Flow (mL/min) (FLOAT), Ferm AA (gal) (FLOAT), Ferm Protease (gal) (FLOAT), Ferm Phytase (gal) (FLOAT), Ferm Antibiotic (lbs) (FLOAT), Ferm Liq Urea (gal) (FLOAT), Ferm Prilled Urea (lbs) (FLOAT), First Yeast Addition (Boxes) (FLOAT), Second Yeast Addition (boxes) (FLOAT), Prop Start Date and Time (DATETIME), Start Fill Date and Time (DATETIME), Drop Date and Time (DATETIME), % Backset to Ferm (FLOAT), Slurry Density (lbs/gal) (FLOAT), Liq Density (lbs/gal) (FLOAT), Prop hours (FLOAT), pH (FLOAT), Brix (FLOAT), Prop Temp (F) (FLOAT), Ferm Vessel Temp (F) (FLOAT), % Budding (FLOAT), Cell Count (FLOAT), % Viability (FLOAT), Total Cells Count (Calc) (FLOAT), Live Cells (FLOAT), Dead Cells (FLOAT), % Viability (Calc) (FLOAT), % DP4 (w/v) (FLOAT), % DP3 (w/v) (FLOAT), % DP2 (w/v) (FLOAT), % Glucose (w/v) (FLOAT), % Lactic Acid (w/v) (FLOAT), % Glycerol (w/v) (FLOAT), % Acetic Acid (w/v) (FLOAT), % Ethanol (w/v) (FLOAT), % Total Sugars (w/v) (FLOAT), Notes (TEXT), .\n",
      "> Table Info: Table 'fermentation_data' has columns: id (INTEGER), age (VARCHAR(50)), date (VARCHAR(50)), am_pm (VARCHAR(25)), ph (VARCHAR(10)), brix (VARCHAR(10)), temp (VARCHAR(10)), total (VARCHAR(10)), live (VARCHAR(10)), dead (VARCHAR(10)), viability (VARCHAR(10)), dp4 (VARCHAR(10)), dp3 (VARCHAR(10)), dp2 (VARCHAR(10)), glucose (VARCHAR(10)), total_sugars (VARCHAR(10)), lactic_acid (VARCHAR(10)), glycerol (VARCHAR(10)), acetic_acid (VARCHAR(10)), ethanol (VARCHAR(10)), tester_initials (VARCHAR(50)), notes (TEXT), date_of_start (VARCHAR(100)), time_of_start (VARCHAR(100)), batch_number (VARCHAR(100)), ferm_number (VARCHAR(100)), .\n",
      "> Table Info: Table 'plc_data_1' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), AMM_3118_PV (DOUBLE), AMM_3118TOT_PV (DOUBLE), AMM_3128_PV (DOUBLE), AMM_3128TOT_PV (DOUBLE), AMM_3138_PV (DOUBLE), AMM_3138TOT_PV (DOUBLE), AMM_3148_PV (DOUBLE), AMM_3148TOT_PV (DOUBLE), DI_3130_PV (DOUBLE), FI_2402_PV (DOUBLE), FI_3150_PV (DOUBLE), FI_3155_PV (DOUBLE), FI_3610_PV (DOUBLE), FI_3801_PV (DOUBLE), FI_3802_PV (DOUBLE), FIC_3513_PV (DOUBLE), FIC_3513_SP (DOUBLE), FIC_3513_VL (DOUBLE), FIC_3801_PV (DOUBLE), FIC_3801_SP (DOUBLE), FIC_3801_VL (DOUBLE), FIC_3803_PV (DOUBLE), FIC_3803_SP (DOUBLE), FIC_3803_VL (DOUBLE), LI_3111_PV (DOUBLE), LI_3121_PV (DOUBLE), LI_3131_PV (DOUBLE), LI_3141_PV (DOUBLE), LI_3501_PV (DOUBLE), LI_3601_PV (DOUBLE), LIC_3801_PV (DOUBLE), LIC_3801_SP (DOUBLE), LIC_3801_VL (DOUBLE), pHIC_2402_PV (DOUBLE), pHIC_2402_SP (DOUBLE), pHIC_2402_VL (DOUBLE), pHIC_3501_PV (DOUBLE), pHIC_3501_SP (DOUBLE), pHIC_3501_VL (DOUBLE), PI_2402_PV (DOUBLE), PI_3801_PV (DOUBLE), TI_3112_PV (DOUBLE), TI_3113_PV (DOUBLE), TI_3122_PV (DOUBLE), TI_3123_PV (DOUBLE), TI_3132_PV (DOUBLE), TI_3133_PV (DOUBLE), TI_3142_PV (DOUBLE), TI_3143_PV (DOUBLE), TI_3501_PV (DOUBLE), .\n",
      "> Table Info: Table 'plc_data_2' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), TI_3801_PV (DOUBLE), TIC_3111_EXT_PV (DOUBLE), TIC_3111_EXT_SP (DOUBLE), TIC_3111_EXT_VL (DOUBLE), TIC_3111B_EXT_PV (DOUBLE), TIC_3111B_EXT_SP (DOUBLE), TIC_3111B_EXT_VL (DOUBLE), TIC_3121_EXT_PV (DOUBLE), TIC_3121_EXT_SP (DOUBLE), TIC_3121_EXT_VL (DOUBLE), TIC_3121B_EXT_PV (DOUBLE), TIC_3121B_EXT_SP (DOUBLE), TIC_3121B_EXT_VL (DOUBLE), TIC_3131_EXT_PV (DOUBLE), TIC_3131_EXT_SP (DOUBLE), TIC_3131_EXT_VL (DOUBLE), TIC_3131B_EXT_PV (DOUBLE), TIC_3131B_EXT_SP (DOUBLE), TIC_3131B_EXT_VL (DOUBLE), TIC_3141_EXT_PV (DOUBLE), TIC_3141_EXT_SP (DOUBLE), TIC_3141_EXT_VL (DOUBLE), TIC_3141B_EXT_PV (DOUBLE), TIC_3141B_EXT_SP (DOUBLE), TIC_3141B_EXT_VL (DOUBLE), TIC_3601_PV (DOUBLE), TIC_3601_SP (DOUBLE), TIC_3601_VL (DOUBLE), TIC_3602_PV (DOUBLE), TIC_3602_SP (DOUBLE), TIC_3602_VL (DOUBLE), DT_2203_PV (DOUBLE), TI_9803_PV (DOUBLE), DT_2402_PV (DOUBLE), LI_2101_PV (DOUBLE), LI_2112_PV (DOUBLE), LI_6801_PV (DOUBLE), LI_6101_PV (DOUBLE), LI_6810_PV (DOUBLE), SC_1401_PV (DOUBLE), PT_1422_PV (DOUBLE), FI_1401_PV (DOUBLE), SIC_11301_OUT (DOUBLE), CD_11301_PV (DOUBLE), FT_11301_PV (DOUBLE), PT_7917_PV (DOUBLE), PT_1313_PV (DOUBLE), CWTOT (DOUBLE), DI_2203_PV (DOUBLE), FT_2203_PV (DOUBLE), FIC_2806_PV (DOUBLE), .\n",
      "> Table Info: Table 'plc_data_3' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), TIC_2203_PV (DOUBLE), FIC_024310B_PV (DOUBLE), II_2261_PV (DOUBLE), II_2262_PV (DOUBLE), TI_2204_PV (DOUBLE), FI_2204_PV (DOUBLE), LIC_2403_PV (DOUBLE), DIC_2402_PV (DOUBLE), FIC_70101_PV (DOUBLE), FIC_70102_PV (DOUBLE), FT_70103_PV (DOUBLE), FIC_70302_PV (DOUBLE), FT_70303_PV (DOUBLE), FIC_70502_PV (DOUBLE), FIC_6220_PV (DOUBLE), FIC_70107_PV (DOUBLE), FIC_70505_PV (DOUBLE), FT_70503_PV (DOUBLE), PT_S_PIT_PV (DOUBLE), ST_70801_PV (DOUBLE), TIC_2405_PV (DOUBLE), TIC_2408_PV (DOUBLE), FIC_2815_PV (DOUBLE), FIC_12415_PV (DOUBLE), FERM_GAP_TOT (DOUBLE), TIC_3601_PV (DOUBLE), FIC_4107_PV (DOUBLE), PI_4107_PV (DOUBLE), LIC_4204_VL (DOUBLE), FIC_4215_PV (DOUBLE), FI_6801_PV (DOUBLE), TI_4410_PV (DOUBLE), TI_4401_PV (DOUBLE), TI_DIFF_PV (DOUBLE), TI_SSDIFF_PV (DOUBLE), TI_4414_PV (DOUBLE), TV_2304_PV (DOUBLE), RECTDIFTMP (DOUBLE), PI_4501_PV (DOUBLE), PIC_4511_PV (DOUBLE), DTFIC_4506_S_PV (DOUBLE), FI_4505_PV (DOUBLE), PIC_4621_PV (DOUBLE), TI_4620_PV (DOUBLE), FIC_8401_PV (DOUBLE), TI_4619_PV (DOUBLE), FI_4613_PV (DOUBLE), LI_8401_PV (DOUBLE), LI_8422_PV (DOUBLE), LI_8433_PV (DOUBLE), II_6202_PV (DOUBLE), .\n",
      "> Table Info: Table 'plc_data_4' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), FIC_6202_PV (DOUBLE), C2_DIFF_SPD (DOUBLE), C2_TORQ (DOUBLE), II_6203_PV (DOUBLE), FIC_6203_PV (DOUBLE), C3_DIFF_SPD (DOUBLE), C3_TORQ (DOUBLE), IT_6254_PV (DOUBLE), FIC_6254_PV (DOUBLE), C4_DIFF_SPD (DOUBLE), C4_TORQ (DOUBLE), FIC_161301_PV (DOUBLE), WT_161310_PV (DOUBLE), ZT_161310 (DOUBLE), FIC_161351_PV (DOUBLE), WT_161360_PV (DOUBLE), ZT_161360 (DOUBLE), LI_77101_PV (DOUBLE), LI_77102_PV (DOUBLE), FI_75802 (DOUBLE), TI_7107_PV (DOUBLE), TI_7103_PV (DOUBLE), FI_7102_PV (DOUBLE), PIC_7102_PV (DOUBLE), TIC_7311_PV (DOUBLE), TIC_7311_OUT (DOUBLE), FT_7306_PV (DOUBLE), FIC_6811_PV (DOUBLE), TI_7772_PV (DOUBLE), TI_7775_PV (DOUBLE), PI_7751_PV (DOUBLE), TI_7872_PV (DOUBLE), TI_7875_PV (DOUBLE), PI_7851_PV (DOUBLE), LI_12101_PV (DOUBLE), LI_12501_PV (DOUBLE), LI_12410_PV (DOUBLE), STEAMPERBEER (DOUBLE), TOT_STM_PERGAL (DOUBLE), TOTALCOOKWATER (DOUBLE), FT_70304_PV (DOUBLE), FT_70504_PV (DOUBLE), FT4613TOT (DOUBLE), FIC_6851_PV (DOUBLE), PT_7930_PV (DOUBLE), TV_4414_PV (DOUBLE), DI_4215_PV (DOUBLE), HT_7311_PV (DOUBLE), RATE_1401_PV (DOUBLE), LI_8403_PV (DOUBLE), LI_2301_PV (DOUBLE), FT4620_STM (DOUBLE), FT4107_STM (DOUBLE), C2_BOWL_CURRENT (DOUBLE), C3_BOWL_CURRENT (DOUBLE), SIEVEEFFIC (DOUBLE), FT1401TOT (DOUBLE), FT11301TOT (DOUBLE), FT_70104_PV (DOUBLE), TV_4414_VL (DOUBLE), .\n",
      "> Table desc str: Table 'DE' has columns: recordid (INTEGER), datetime (DATETIME), date (DATE), shift (VARCHAR(50)), operator (VARCHAR(50)), hour (VARCHAR(100)), category (VARCHAR(50)), parameter (VARCHAR(50)), target (VARCHAR(50)), entered_value (VARCHAR(50)), user (VARCHAR(50)), .\n",
      "\n",
      "Table 'HPLC_Data' has columns: Quarter (VARCHAR(10)), Ferm Drop Month (VARCHAR(20)), Ferm No (VARCHAR(10)), Batch No (VARCHAR(20)), Ferm Hour (VARCHAR(50)), Sample Description (VARCHAR(50)), Prop Mash % Solids (FLOAT), Prop Urea (lbs) (FLOAT), Prop Antibiotic (lbs) (FLOAT), Prop GA (gal) (FLOAT), Prop Protease (gal) (FLOAT), Ferm GA 1st Add. (gal) (FLOAT), Ferm GA 2nd Add (gal) (FLOAT), Ferm GA Flow (mL/min) (FLOAT), Ferm Fill Time (hrs) (FLOAT), GA Meter Add. (gal) (FLOAT), Total Ferm GA (gal) (FLOAT), Ferm AA Flow (mL/min) (FLOAT), Ferm AA (gal) (FLOAT), Ferm Protease (gal) (FLOAT), Ferm Phytase (gal) (FLOAT), Ferm Antibiotic (lbs) (FLOAT), Ferm Liq Urea (gal) (FLOAT), Ferm Prilled Urea (lbs) (FLOAT), First Yeast Addition (Boxes) (FLOAT), Second Yeast Addition (boxes) (FLOAT), Prop Start Date and Time (DATETIME), Start Fill Date and Time (DATETIME), Drop Date and Time (DATETIME), % Backset to Ferm (FLOAT), Slurry Density (lbs/gal) (FLOAT), Liq Density (lbs/gal) (FLOAT), Prop hours (FLOAT), pH (FLOAT), Brix (FLOAT), Prop Temp (F) (FLOAT), Ferm Vessel Temp (F) (FLOAT), % Budding (FLOAT), Cell Count (FLOAT), % Viability (FLOAT), Total Cells Count (Calc) (FLOAT), Live Cells (FLOAT), Dead Cells (FLOAT), % Viability (Calc) (FLOAT), % DP4 (w/v) (FLOAT), % DP3 (w/v) (FLOAT), % DP2 (w/v) (FLOAT), % Glucose (w/v) (FLOAT), % Lactic Acid (w/v) (FLOAT), % Glycerol (w/v) (FLOAT), % Acetic Acid (w/v) (FLOAT), % Ethanol (w/v) (FLOAT), % Total Sugars (w/v) (FLOAT), Notes (TEXT), .\n",
      "\n",
      "Table 'fermentation_data' has columns: id (INTEGER), age (VARCHAR(50)), date (VARCHAR(50)), am_pm (VARCHAR(25)), ph (VARCHAR(10)), brix (VARCHAR(10)), temp (VARCHAR(10)), total (VARCHAR(10)), live (VARCHAR(10)), dead (VARCHAR(10)), viability (VARCHAR(10)), dp4 (VARCHAR(10)), dp3 (VARCHAR(10)), dp2 (VARCHAR(10)), glucose (VARCHAR(10)), total_sugars (VARCHAR(10)), lactic_acid (VARCHAR(10)), glycerol (VARCHAR(10)), acetic_acid (VARCHAR(10)), ethanol (VARCHAR(10)), tester_initials (VARCHAR(50)), notes (TEXT), date_of_start (VARCHAR(100)), time_of_start (VARCHAR(100)), batch_number (VARCHAR(100)), ferm_number (VARCHAR(100)), .\n",
      "\n",
      "Table 'plc_data_1' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), AMM_3118_PV (DOUBLE), AMM_3118TOT_PV (DOUBLE), AMM_3128_PV (DOUBLE), AMM_3128TOT_PV (DOUBLE), AMM_3138_PV (DOUBLE), AMM_3138TOT_PV (DOUBLE), AMM_3148_PV (DOUBLE), AMM_3148TOT_PV (DOUBLE), DI_3130_PV (DOUBLE), FI_2402_PV (DOUBLE), FI_3150_PV (DOUBLE), FI_3155_PV (DOUBLE), FI_3610_PV (DOUBLE), FI_3801_PV (DOUBLE), FI_3802_PV (DOUBLE), FIC_3513_PV (DOUBLE), FIC_3513_SP (DOUBLE), FIC_3513_VL (DOUBLE), FIC_3801_PV (DOUBLE), FIC_3801_SP (DOUBLE), FIC_3801_VL (DOUBLE), FIC_3803_PV (DOUBLE), FIC_3803_SP (DOUBLE), FIC_3803_VL (DOUBLE), LI_3111_PV (DOUBLE), LI_3121_PV (DOUBLE), LI_3131_PV (DOUBLE), LI_3141_PV (DOUBLE), LI_3501_PV (DOUBLE), LI_3601_PV (DOUBLE), LIC_3801_PV (DOUBLE), LIC_3801_SP (DOUBLE), LIC_3801_VL (DOUBLE), pHIC_2402_PV (DOUBLE), pHIC_2402_SP (DOUBLE), pHIC_2402_VL (DOUBLE), pHIC_3501_PV (DOUBLE), pHIC_3501_SP (DOUBLE), pHIC_3501_VL (DOUBLE), PI_2402_PV (DOUBLE), PI_3801_PV (DOUBLE), TI_3112_PV (DOUBLE), TI_3113_PV (DOUBLE), TI_3122_PV (DOUBLE), TI_3123_PV (DOUBLE), TI_3132_PV (DOUBLE), TI_3133_PV (DOUBLE), TI_3142_PV (DOUBLE), TI_3143_PV (DOUBLE), TI_3501_PV (DOUBLE), .\n",
      "\n",
      "Table 'plc_data_2' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), TI_3801_PV (DOUBLE), TIC_3111_EXT_PV (DOUBLE), TIC_3111_EXT_SP (DOUBLE), TIC_3111_EXT_VL (DOUBLE), TIC_3111B_EXT_PV (DOUBLE), TIC_3111B_EXT_SP (DOUBLE), TIC_3111B_EXT_VL (DOUBLE), TIC_3121_EXT_PV (DOUBLE), TIC_3121_EXT_SP (DOUBLE), TIC_3121_EXT_VL (DOUBLE), TIC_3121B_EXT_PV (DOUBLE), TIC_3121B_EXT_SP (DOUBLE), TIC_3121B_EXT_VL (DOUBLE), TIC_3131_EXT_PV (DOUBLE), TIC_3131_EXT_SP (DOUBLE), TIC_3131_EXT_VL (DOUBLE), TIC_3131B_EXT_PV (DOUBLE), TIC_3131B_EXT_SP (DOUBLE), TIC_3131B_EXT_VL (DOUBLE), TIC_3141_EXT_PV (DOUBLE), TIC_3141_EXT_SP (DOUBLE), TIC_3141_EXT_VL (DOUBLE), TIC_3141B_EXT_PV (DOUBLE), TIC_3141B_EXT_SP (DOUBLE), TIC_3141B_EXT_VL (DOUBLE), TIC_3601_PV (DOUBLE), TIC_3601_SP (DOUBLE), TIC_3601_VL (DOUBLE), TIC_3602_PV (DOUBLE), TIC_3602_SP (DOUBLE), TIC_3602_VL (DOUBLE), DT_2203_PV (DOUBLE), TI_9803_PV (DOUBLE), DT_2402_PV (DOUBLE), LI_2101_PV (DOUBLE), LI_2112_PV (DOUBLE), LI_6801_PV (DOUBLE), LI_6101_PV (DOUBLE), LI_6810_PV (DOUBLE), SC_1401_PV (DOUBLE), PT_1422_PV (DOUBLE), FI_1401_PV (DOUBLE), SIC_11301_OUT (DOUBLE), CD_11301_PV (DOUBLE), FT_11301_PV (DOUBLE), PT_7917_PV (DOUBLE), PT_1313_PV (DOUBLE), CWTOT (DOUBLE), DI_2203_PV (DOUBLE), FT_2203_PV (DOUBLE), FIC_2806_PV (DOUBLE), .\n",
      "\n",
      "Table 'plc_data_3' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), TIC_2203_PV (DOUBLE), FIC_024310B_PV (DOUBLE), II_2261_PV (DOUBLE), II_2262_PV (DOUBLE), TI_2204_PV (DOUBLE), FI_2204_PV (DOUBLE), LIC_2403_PV (DOUBLE), DIC_2402_PV (DOUBLE), FIC_70101_PV (DOUBLE), FIC_70102_PV (DOUBLE), FT_70103_PV (DOUBLE), FIC_70302_PV (DOUBLE), FT_70303_PV (DOUBLE), FIC_70502_PV (DOUBLE), FIC_6220_PV (DOUBLE), FIC_70107_PV (DOUBLE), FIC_70505_PV (DOUBLE), FT_70503_PV (DOUBLE), PT_S_PIT_PV (DOUBLE), ST_70801_PV (DOUBLE), TIC_2405_PV (DOUBLE), TIC_2408_PV (DOUBLE), FIC_2815_PV (DOUBLE), FIC_12415_PV (DOUBLE), FERM_GAP_TOT (DOUBLE), TIC_3601_PV (DOUBLE), FIC_4107_PV (DOUBLE), PI_4107_PV (DOUBLE), LIC_4204_VL (DOUBLE), FIC_4215_PV (DOUBLE), FI_6801_PV (DOUBLE), TI_4410_PV (DOUBLE), TI_4401_PV (DOUBLE), TI_DIFF_PV (DOUBLE), TI_SSDIFF_PV (DOUBLE), TI_4414_PV (DOUBLE), TV_2304_PV (DOUBLE), RECTDIFTMP (DOUBLE), PI_4501_PV (DOUBLE), PIC_4511_PV (DOUBLE), DTFIC_4506_S_PV (DOUBLE), FI_4505_PV (DOUBLE), PIC_4621_PV (DOUBLE), TI_4620_PV (DOUBLE), FIC_8401_PV (DOUBLE), TI_4619_PV (DOUBLE), FI_4613_PV (DOUBLE), LI_8401_PV (DOUBLE), LI_8422_PV (DOUBLE), LI_8433_PV (DOUBLE), II_6202_PV (DOUBLE), .\n",
      "\n",
      "Table 'plc_data_4' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), FIC_6202_PV (DOUBLE), C2_DIFF_SPD (DOUBLE), C2_TORQ (DOUBLE), II_6203_PV (DOUBLE), FIC_6203_PV (DOUBLE), C3_DIFF_SPD (DOUBLE), C3_TORQ (DOUBLE), IT_6254_PV (DOUBLE), FIC_6254_PV (DOUBLE), C4_DIFF_SPD (DOUBLE), C4_TORQ (DOUBLE), FIC_161301_PV (DOUBLE), WT_161310_PV (DOUBLE), ZT_161310 (DOUBLE), FIC_161351_PV (DOUBLE), WT_161360_PV (DOUBLE), ZT_161360 (DOUBLE), LI_77101_PV (DOUBLE), LI_77102_PV (DOUBLE), FI_75802 (DOUBLE), TI_7107_PV (DOUBLE), TI_7103_PV (DOUBLE), FI_7102_PV (DOUBLE), PIC_7102_PV (DOUBLE), TIC_7311_PV (DOUBLE), TIC_7311_OUT (DOUBLE), FT_7306_PV (DOUBLE), FIC_6811_PV (DOUBLE), TI_7772_PV (DOUBLE), TI_7775_PV (DOUBLE), PI_7751_PV (DOUBLE), TI_7872_PV (DOUBLE), TI_7875_PV (DOUBLE), PI_7851_PV (DOUBLE), LI_12101_PV (DOUBLE), LI_12501_PV (DOUBLE), LI_12410_PV (DOUBLE), STEAMPERBEER (DOUBLE), TOT_STM_PERGAL (DOUBLE), TOTALCOOKWATER (DOUBLE), FT_70304_PV (DOUBLE), FT_70504_PV (DOUBLE), FT4613TOT (DOUBLE), FIC_6851_PV (DOUBLE), PT_7930_PV (DOUBLE), TV_4414_PV (DOUBLE), DI_4215_PV (DOUBLE), HT_7311_PV (DOUBLE), RATE_1401_PV (DOUBLE), LI_8403_PV (DOUBLE), LI_2301_PV (DOUBLE), FT4620_STM (DOUBLE), FT4107_STM (DOUBLE), C2_BOWL_CURRENT (DOUBLE), C3_BOWL_CURRENT (DOUBLE), SIEVEEFFIC (DOUBLE), FT1401TOT (DOUBLE), FT11301TOT (DOUBLE), FT_70104_PV (DOUBLE), TV_4414_VL (DOUBLE), .\n",
      "> Predicted SQL query: SELECT recordid, datetime, date, shift, operator, category, parameter, target, entered_value, user FROM DE WHERE datetime >= DATE_SUB(CURDATE(), INTERVAL 1 DAY) ORDER BY datetime DESC;\n",
      "> Refine context: 2, 18, 6, 18, 42), datetime.date(2025, 2, 17), ...\n",
      "> Refine context: 'admin'), (1894, datetime.datetime(2025, 2, 18,...\n",
      "> Refine context: (1855, datetime.datetime(2025, 2, 17, 8, 41, 50...\n",
      "> Refine context: 6, 9, 27), datetime.date(2025, 2, 16), 'A', 'CO...\n",
      "\u001b[1;3;38;2;155;135;227m> Running module output_component with input: \n",
      "output: The provided context doesn't seem to directly relate to downtime records for equipment. However, based on your request and the new natural language query, I will refine the SQL query to ensure it is a...\n",
      "\n",
      "\u001b[0m> Inferred SQL Query: SELECT recordid, datetime, date, shift, operator, category, parameter, target, entered_value, user FROM DE WHERE datetime >= DATE_SUB(CURDATE(), INTERVAL 1 DAY) ORDER BY datetime DESC;\n",
      "> SQL Response: The provided context doesn't seem to directly relate to downtime records for equipment. However, based on your request and the new natural language query, I will refine the SQL query to ensure it is as clear and accurate as possible.\n",
      "\n",
      "### Refined SQL Query:\n",
      "```sql\n",
      "SELECT \n",
      "    equipment_id, \n",
      "    downtime_start, \n",
      "    downtime_end, \n",
      "    reason_for_downtime\n",
      "FROM \n",
      "    equipment_downtime\n",
      "WHERE \n",
      "    downtime_start >= NOW() - INTERVAL '24 HOURS'\n",
      "ORDER BY \n",
      "    downtime_start DESC;\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- **equipment_id**: The unique identifier for the equipment.\n",
      "- **downtime_start**: The timestamp when the downtime started.\n",
      "- **downtime_end**: The timestamp when the downtime ended (if applicable).\n",
      "- **reason_for_downtime**: A description or reason for the downtime.\n",
      "\n",
      "This query selects all records from the `equipment_downtime` table where the `downtime_start` is within the last 24 hours. It then orders the results by the `downtime_start` timestamp in descending order to show the most recent downtimes first.\n",
      "\n",
      "If you have any specific requirements or need further customization, please let me know!\n",
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module retry_prompt with input: \n",
      "input: Downtime on equipment last 24 hours ?\n",
      "convo_history: User: Downtime on equipment last 24 hours ?\n",
      "Assistant (inferred SQL query): SELECT recordid, datetime, date, shift, operator, category, parameter, target, entered_value, user FROM DE WHERE datetime >=...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm with input: \n",
      "messages: You are trying to generate a proper natural language query given a user input.\n",
      "\n",
      "This query will then be interpreted by a downstream text-to-SQL agent which\n",
      "will convert the query to a SQL statement. I...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module sql_query_engine with input: \n",
      "input: assistant: Given the user's request and the conversation history, I will generate a new natural language query that avoids the issues of the previous SQL query.\n",
      "\n",
      "### New Natural Language Query:\n",
      "\"Retri...\n",
      "\n",
      "\u001b[0m> Table Info: Table 'DE' has columns: recordid (INTEGER), datetime (DATETIME), date (DATE), shift (VARCHAR(50)), operator (VARCHAR(50)), hour (VARCHAR(100)), category (VARCHAR(50)), parameter (VARCHAR(50)), target (VARCHAR(50)), entered_value (VARCHAR(50)), user (VARCHAR(50)), .\n",
      "> Table Info: Table 'HPLC_Data' has columns: Quarter (VARCHAR(10)), Ferm Drop Month (VARCHAR(20)), Ferm No (VARCHAR(10)), Batch No (VARCHAR(20)), Ferm Hour (VARCHAR(50)), Sample Description (VARCHAR(50)), Prop Mash % Solids (FLOAT), Prop Urea (lbs) (FLOAT), Prop Antibiotic (lbs) (FLOAT), Prop GA (gal) (FLOAT), Prop Protease (gal) (FLOAT), Ferm GA 1st Add. (gal) (FLOAT), Ferm GA 2nd Add (gal) (FLOAT), Ferm GA Flow (mL/min) (FLOAT), Ferm Fill Time (hrs) (FLOAT), GA Meter Add. (gal) (FLOAT), Total Ferm GA (gal) (FLOAT), Ferm AA Flow (mL/min) (FLOAT), Ferm AA (gal) (FLOAT), Ferm Protease (gal) (FLOAT), Ferm Phytase (gal) (FLOAT), Ferm Antibiotic (lbs) (FLOAT), Ferm Liq Urea (gal) (FLOAT), Ferm Prilled Urea (lbs) (FLOAT), First Yeast Addition (Boxes) (FLOAT), Second Yeast Addition (boxes) (FLOAT), Prop Start Date and Time (DATETIME), Start Fill Date and Time (DATETIME), Drop Date and Time (DATETIME), % Backset to Ferm (FLOAT), Slurry Density (lbs/gal) (FLOAT), Liq Density (lbs/gal) (FLOAT), Prop hours (FLOAT), pH (FLOAT), Brix (FLOAT), Prop Temp (F) (FLOAT), Ferm Vessel Temp (F) (FLOAT), % Budding (FLOAT), Cell Count (FLOAT), % Viability (FLOAT), Total Cells Count (Calc) (FLOAT), Live Cells (FLOAT), Dead Cells (FLOAT), % Viability (Calc) (FLOAT), % DP4 (w/v) (FLOAT), % DP3 (w/v) (FLOAT), % DP2 (w/v) (FLOAT), % Glucose (w/v) (FLOAT), % Lactic Acid (w/v) (FLOAT), % Glycerol (w/v) (FLOAT), % Acetic Acid (w/v) (FLOAT), % Ethanol (w/v) (FLOAT), % Total Sugars (w/v) (FLOAT), Notes (TEXT), .\n",
      "> Table Info: Table 'fermentation_data' has columns: id (INTEGER), age (VARCHAR(50)), date (VARCHAR(50)), am_pm (VARCHAR(25)), ph (VARCHAR(10)), brix (VARCHAR(10)), temp (VARCHAR(10)), total (VARCHAR(10)), live (VARCHAR(10)), dead (VARCHAR(10)), viability (VARCHAR(10)), dp4 (VARCHAR(10)), dp3 (VARCHAR(10)), dp2 (VARCHAR(10)), glucose (VARCHAR(10)), total_sugars (VARCHAR(10)), lactic_acid (VARCHAR(10)), glycerol (VARCHAR(10)), acetic_acid (VARCHAR(10)), ethanol (VARCHAR(10)), tester_initials (VARCHAR(50)), notes (TEXT), date_of_start (VARCHAR(100)), time_of_start (VARCHAR(100)), batch_number (VARCHAR(100)), ferm_number (VARCHAR(100)), .\n",
      "> Table Info: Table 'plc_data_1' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), AMM_3118_PV (DOUBLE), AMM_3118TOT_PV (DOUBLE), AMM_3128_PV (DOUBLE), AMM_3128TOT_PV (DOUBLE), AMM_3138_PV (DOUBLE), AMM_3138TOT_PV (DOUBLE), AMM_3148_PV (DOUBLE), AMM_3148TOT_PV (DOUBLE), DI_3130_PV (DOUBLE), FI_2402_PV (DOUBLE), FI_3150_PV (DOUBLE), FI_3155_PV (DOUBLE), FI_3610_PV (DOUBLE), FI_3801_PV (DOUBLE), FI_3802_PV (DOUBLE), FIC_3513_PV (DOUBLE), FIC_3513_SP (DOUBLE), FIC_3513_VL (DOUBLE), FIC_3801_PV (DOUBLE), FIC_3801_SP (DOUBLE), FIC_3801_VL (DOUBLE), FIC_3803_PV (DOUBLE), FIC_3803_SP (DOUBLE), FIC_3803_VL (DOUBLE), LI_3111_PV (DOUBLE), LI_3121_PV (DOUBLE), LI_3131_PV (DOUBLE), LI_3141_PV (DOUBLE), LI_3501_PV (DOUBLE), LI_3601_PV (DOUBLE), LIC_3801_PV (DOUBLE), LIC_3801_SP (DOUBLE), LIC_3801_VL (DOUBLE), pHIC_2402_PV (DOUBLE), pHIC_2402_SP (DOUBLE), pHIC_2402_VL (DOUBLE), pHIC_3501_PV (DOUBLE), pHIC_3501_SP (DOUBLE), pHIC_3501_VL (DOUBLE), PI_2402_PV (DOUBLE), PI_3801_PV (DOUBLE), TI_3112_PV (DOUBLE), TI_3113_PV (DOUBLE), TI_3122_PV (DOUBLE), TI_3123_PV (DOUBLE), TI_3132_PV (DOUBLE), TI_3133_PV (DOUBLE), TI_3142_PV (DOUBLE), TI_3143_PV (DOUBLE), TI_3501_PV (DOUBLE), .\n",
      "> Table Info: Table 'plc_data_2' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), TI_3801_PV (DOUBLE), TIC_3111_EXT_PV (DOUBLE), TIC_3111_EXT_SP (DOUBLE), TIC_3111_EXT_VL (DOUBLE), TIC_3111B_EXT_PV (DOUBLE), TIC_3111B_EXT_SP (DOUBLE), TIC_3111B_EXT_VL (DOUBLE), TIC_3121_EXT_PV (DOUBLE), TIC_3121_EXT_SP (DOUBLE), TIC_3121_EXT_VL (DOUBLE), TIC_3121B_EXT_PV (DOUBLE), TIC_3121B_EXT_SP (DOUBLE), TIC_3121B_EXT_VL (DOUBLE), TIC_3131_EXT_PV (DOUBLE), TIC_3131_EXT_SP (DOUBLE), TIC_3131_EXT_VL (DOUBLE), TIC_3131B_EXT_PV (DOUBLE), TIC_3131B_EXT_SP (DOUBLE), TIC_3131B_EXT_VL (DOUBLE), TIC_3141_EXT_PV (DOUBLE), TIC_3141_EXT_SP (DOUBLE), TIC_3141_EXT_VL (DOUBLE), TIC_3141B_EXT_PV (DOUBLE), TIC_3141B_EXT_SP (DOUBLE), TIC_3141B_EXT_VL (DOUBLE), TIC_3601_PV (DOUBLE), TIC_3601_SP (DOUBLE), TIC_3601_VL (DOUBLE), TIC_3602_PV (DOUBLE), TIC_3602_SP (DOUBLE), TIC_3602_VL (DOUBLE), DT_2203_PV (DOUBLE), TI_9803_PV (DOUBLE), DT_2402_PV (DOUBLE), LI_2101_PV (DOUBLE), LI_2112_PV (DOUBLE), LI_6801_PV (DOUBLE), LI_6101_PV (DOUBLE), LI_6810_PV (DOUBLE), SC_1401_PV (DOUBLE), PT_1422_PV (DOUBLE), FI_1401_PV (DOUBLE), SIC_11301_OUT (DOUBLE), CD_11301_PV (DOUBLE), FT_11301_PV (DOUBLE), PT_7917_PV (DOUBLE), PT_1313_PV (DOUBLE), CWTOT (DOUBLE), DI_2203_PV (DOUBLE), FT_2203_PV (DOUBLE), FIC_2806_PV (DOUBLE), .\n",
      "> Table Info: Table 'plc_data_3' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), TIC_2203_PV (DOUBLE), FIC_024310B_PV (DOUBLE), II_2261_PV (DOUBLE), II_2262_PV (DOUBLE), TI_2204_PV (DOUBLE), FI_2204_PV (DOUBLE), LIC_2403_PV (DOUBLE), DIC_2402_PV (DOUBLE), FIC_70101_PV (DOUBLE), FIC_70102_PV (DOUBLE), FT_70103_PV (DOUBLE), FIC_70302_PV (DOUBLE), FT_70303_PV (DOUBLE), FIC_70502_PV (DOUBLE), FIC_6220_PV (DOUBLE), FIC_70107_PV (DOUBLE), FIC_70505_PV (DOUBLE), FT_70503_PV (DOUBLE), PT_S_PIT_PV (DOUBLE), ST_70801_PV (DOUBLE), TIC_2405_PV (DOUBLE), TIC_2408_PV (DOUBLE), FIC_2815_PV (DOUBLE), FIC_12415_PV (DOUBLE), FERM_GAP_TOT (DOUBLE), TIC_3601_PV (DOUBLE), FIC_4107_PV (DOUBLE), PI_4107_PV (DOUBLE), LIC_4204_VL (DOUBLE), FIC_4215_PV (DOUBLE), FI_6801_PV (DOUBLE), TI_4410_PV (DOUBLE), TI_4401_PV (DOUBLE), TI_DIFF_PV (DOUBLE), TI_SSDIFF_PV (DOUBLE), TI_4414_PV (DOUBLE), TV_2304_PV (DOUBLE), RECTDIFTMP (DOUBLE), PI_4501_PV (DOUBLE), PIC_4511_PV (DOUBLE), DTFIC_4506_S_PV (DOUBLE), FI_4505_PV (DOUBLE), PIC_4621_PV (DOUBLE), TI_4620_PV (DOUBLE), FIC_8401_PV (DOUBLE), TI_4619_PV (DOUBLE), FI_4613_PV (DOUBLE), LI_8401_PV (DOUBLE), LI_8422_PV (DOUBLE), LI_8433_PV (DOUBLE), II_6202_PV (DOUBLE), .\n",
      "> Table Info: Table 'plc_data_4' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), FIC_6202_PV (DOUBLE), C2_DIFF_SPD (DOUBLE), C2_TORQ (DOUBLE), II_6203_PV (DOUBLE), FIC_6203_PV (DOUBLE), C3_DIFF_SPD (DOUBLE), C3_TORQ (DOUBLE), IT_6254_PV (DOUBLE), FIC_6254_PV (DOUBLE), C4_DIFF_SPD (DOUBLE), C4_TORQ (DOUBLE), FIC_161301_PV (DOUBLE), WT_161310_PV (DOUBLE), ZT_161310 (DOUBLE), FIC_161351_PV (DOUBLE), WT_161360_PV (DOUBLE), ZT_161360 (DOUBLE), LI_77101_PV (DOUBLE), LI_77102_PV (DOUBLE), FI_75802 (DOUBLE), TI_7107_PV (DOUBLE), TI_7103_PV (DOUBLE), FI_7102_PV (DOUBLE), PIC_7102_PV (DOUBLE), TIC_7311_PV (DOUBLE), TIC_7311_OUT (DOUBLE), FT_7306_PV (DOUBLE), FIC_6811_PV (DOUBLE), TI_7772_PV (DOUBLE), TI_7775_PV (DOUBLE), PI_7751_PV (DOUBLE), TI_7872_PV (DOUBLE), TI_7875_PV (DOUBLE), PI_7851_PV (DOUBLE), LI_12101_PV (DOUBLE), LI_12501_PV (DOUBLE), LI_12410_PV (DOUBLE), STEAMPERBEER (DOUBLE), TOT_STM_PERGAL (DOUBLE), TOTALCOOKWATER (DOUBLE), FT_70304_PV (DOUBLE), FT_70504_PV (DOUBLE), FT4613TOT (DOUBLE), FIC_6851_PV (DOUBLE), PT_7930_PV (DOUBLE), TV_4414_PV (DOUBLE), DI_4215_PV (DOUBLE), HT_7311_PV (DOUBLE), RATE_1401_PV (DOUBLE), LI_8403_PV (DOUBLE), LI_2301_PV (DOUBLE), FT4620_STM (DOUBLE), FT4107_STM (DOUBLE), C2_BOWL_CURRENT (DOUBLE), C3_BOWL_CURRENT (DOUBLE), SIEVEEFFIC (DOUBLE), FT1401TOT (DOUBLE), FT11301TOT (DOUBLE), FT_70104_PV (DOUBLE), TV_4414_VL (DOUBLE), .\n",
      "> Table desc str: Table 'DE' has columns: recordid (INTEGER), datetime (DATETIME), date (DATE), shift (VARCHAR(50)), operator (VARCHAR(50)), hour (VARCHAR(100)), category (VARCHAR(50)), parameter (VARCHAR(50)), target (VARCHAR(50)), entered_value (VARCHAR(50)), user (VARCHAR(50)), .\n",
      "\n",
      "Table 'HPLC_Data' has columns: Quarter (VARCHAR(10)), Ferm Drop Month (VARCHAR(20)), Ferm No (VARCHAR(10)), Batch No (VARCHAR(20)), Ferm Hour (VARCHAR(50)), Sample Description (VARCHAR(50)), Prop Mash % Solids (FLOAT), Prop Urea (lbs) (FLOAT), Prop Antibiotic (lbs) (FLOAT), Prop GA (gal) (FLOAT), Prop Protease (gal) (FLOAT), Ferm GA 1st Add. (gal) (FLOAT), Ferm GA 2nd Add (gal) (FLOAT), Ferm GA Flow (mL/min) (FLOAT), Ferm Fill Time (hrs) (FLOAT), GA Meter Add. (gal) (FLOAT), Total Ferm GA (gal) (FLOAT), Ferm AA Flow (mL/min) (FLOAT), Ferm AA (gal) (FLOAT), Ferm Protease (gal) (FLOAT), Ferm Phytase (gal) (FLOAT), Ferm Antibiotic (lbs) (FLOAT), Ferm Liq Urea (gal) (FLOAT), Ferm Prilled Urea (lbs) (FLOAT), First Yeast Addition (Boxes) (FLOAT), Second Yeast Addition (boxes) (FLOAT), Prop Start Date and Time (DATETIME), Start Fill Date and Time (DATETIME), Drop Date and Time (DATETIME), % Backset to Ferm (FLOAT), Slurry Density (lbs/gal) (FLOAT), Liq Density (lbs/gal) (FLOAT), Prop hours (FLOAT), pH (FLOAT), Brix (FLOAT), Prop Temp (F) (FLOAT), Ferm Vessel Temp (F) (FLOAT), % Budding (FLOAT), Cell Count (FLOAT), % Viability (FLOAT), Total Cells Count (Calc) (FLOAT), Live Cells (FLOAT), Dead Cells (FLOAT), % Viability (Calc) (FLOAT), % DP4 (w/v) (FLOAT), % DP3 (w/v) (FLOAT), % DP2 (w/v) (FLOAT), % Glucose (w/v) (FLOAT), % Lactic Acid (w/v) (FLOAT), % Glycerol (w/v) (FLOAT), % Acetic Acid (w/v) (FLOAT), % Ethanol (w/v) (FLOAT), % Total Sugars (w/v) (FLOAT), Notes (TEXT), .\n",
      "\n",
      "Table 'fermentation_data' has columns: id (INTEGER), age (VARCHAR(50)), date (VARCHAR(50)), am_pm (VARCHAR(25)), ph (VARCHAR(10)), brix (VARCHAR(10)), temp (VARCHAR(10)), total (VARCHAR(10)), live (VARCHAR(10)), dead (VARCHAR(10)), viability (VARCHAR(10)), dp4 (VARCHAR(10)), dp3 (VARCHAR(10)), dp2 (VARCHAR(10)), glucose (VARCHAR(10)), total_sugars (VARCHAR(10)), lactic_acid (VARCHAR(10)), glycerol (VARCHAR(10)), acetic_acid (VARCHAR(10)), ethanol (VARCHAR(10)), tester_initials (VARCHAR(50)), notes (TEXT), date_of_start (VARCHAR(100)), time_of_start (VARCHAR(100)), batch_number (VARCHAR(100)), ferm_number (VARCHAR(100)), .\n",
      "\n",
      "Table 'plc_data_1' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), AMM_3118_PV (DOUBLE), AMM_3118TOT_PV (DOUBLE), AMM_3128_PV (DOUBLE), AMM_3128TOT_PV (DOUBLE), AMM_3138_PV (DOUBLE), AMM_3138TOT_PV (DOUBLE), AMM_3148_PV (DOUBLE), AMM_3148TOT_PV (DOUBLE), DI_3130_PV (DOUBLE), FI_2402_PV (DOUBLE), FI_3150_PV (DOUBLE), FI_3155_PV (DOUBLE), FI_3610_PV (DOUBLE), FI_3801_PV (DOUBLE), FI_3802_PV (DOUBLE), FIC_3513_PV (DOUBLE), FIC_3513_SP (DOUBLE), FIC_3513_VL (DOUBLE), FIC_3801_PV (DOUBLE), FIC_3801_SP (DOUBLE), FIC_3801_VL (DOUBLE), FIC_3803_PV (DOUBLE), FIC_3803_SP (DOUBLE), FIC_3803_VL (DOUBLE), LI_3111_PV (DOUBLE), LI_3121_PV (DOUBLE), LI_3131_PV (DOUBLE), LI_3141_PV (DOUBLE), LI_3501_PV (DOUBLE), LI_3601_PV (DOUBLE), LIC_3801_PV (DOUBLE), LIC_3801_SP (DOUBLE), LIC_3801_VL (DOUBLE), pHIC_2402_PV (DOUBLE), pHIC_2402_SP (DOUBLE), pHIC_2402_VL (DOUBLE), pHIC_3501_PV (DOUBLE), pHIC_3501_SP (DOUBLE), pHIC_3501_VL (DOUBLE), PI_2402_PV (DOUBLE), PI_3801_PV (DOUBLE), TI_3112_PV (DOUBLE), TI_3113_PV (DOUBLE), TI_3122_PV (DOUBLE), TI_3123_PV (DOUBLE), TI_3132_PV (DOUBLE), TI_3133_PV (DOUBLE), TI_3142_PV (DOUBLE), TI_3143_PV (DOUBLE), TI_3501_PV (DOUBLE), .\n",
      "\n",
      "Table 'plc_data_2' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), TI_3801_PV (DOUBLE), TIC_3111_EXT_PV (DOUBLE), TIC_3111_EXT_SP (DOUBLE), TIC_3111_EXT_VL (DOUBLE), TIC_3111B_EXT_PV (DOUBLE), TIC_3111B_EXT_SP (DOUBLE), TIC_3111B_EXT_VL (DOUBLE), TIC_3121_EXT_PV (DOUBLE), TIC_3121_EXT_SP (DOUBLE), TIC_3121_EXT_VL (DOUBLE), TIC_3121B_EXT_PV (DOUBLE), TIC_3121B_EXT_SP (DOUBLE), TIC_3121B_EXT_VL (DOUBLE), TIC_3131_EXT_PV (DOUBLE), TIC_3131_EXT_SP (DOUBLE), TIC_3131_EXT_VL (DOUBLE), TIC_3131B_EXT_PV (DOUBLE), TIC_3131B_EXT_SP (DOUBLE), TIC_3131B_EXT_VL (DOUBLE), TIC_3141_EXT_PV (DOUBLE), TIC_3141_EXT_SP (DOUBLE), TIC_3141_EXT_VL (DOUBLE), TIC_3141B_EXT_PV (DOUBLE), TIC_3141B_EXT_SP (DOUBLE), TIC_3141B_EXT_VL (DOUBLE), TIC_3601_PV (DOUBLE), TIC_3601_SP (DOUBLE), TIC_3601_VL (DOUBLE), TIC_3602_PV (DOUBLE), TIC_3602_SP (DOUBLE), TIC_3602_VL (DOUBLE), DT_2203_PV (DOUBLE), TI_9803_PV (DOUBLE), DT_2402_PV (DOUBLE), LI_2101_PV (DOUBLE), LI_2112_PV (DOUBLE), LI_6801_PV (DOUBLE), LI_6101_PV (DOUBLE), LI_6810_PV (DOUBLE), SC_1401_PV (DOUBLE), PT_1422_PV (DOUBLE), FI_1401_PV (DOUBLE), SIC_11301_OUT (DOUBLE), CD_11301_PV (DOUBLE), FT_11301_PV (DOUBLE), PT_7917_PV (DOUBLE), PT_1313_PV (DOUBLE), CWTOT (DOUBLE), DI_2203_PV (DOUBLE), FT_2203_PV (DOUBLE), FIC_2806_PV (DOUBLE), .\n",
      "\n",
      "Table 'plc_data_3' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), TIC_2203_PV (DOUBLE), FIC_024310B_PV (DOUBLE), II_2261_PV (DOUBLE), II_2262_PV (DOUBLE), TI_2204_PV (DOUBLE), FI_2204_PV (DOUBLE), LIC_2403_PV (DOUBLE), DIC_2402_PV (DOUBLE), FIC_70101_PV (DOUBLE), FIC_70102_PV (DOUBLE), FT_70103_PV (DOUBLE), FIC_70302_PV (DOUBLE), FT_70303_PV (DOUBLE), FIC_70502_PV (DOUBLE), FIC_6220_PV (DOUBLE), FIC_70107_PV (DOUBLE), FIC_70505_PV (DOUBLE), FT_70503_PV (DOUBLE), PT_S_PIT_PV (DOUBLE), ST_70801_PV (DOUBLE), TIC_2405_PV (DOUBLE), TIC_2408_PV (DOUBLE), FIC_2815_PV (DOUBLE), FIC_12415_PV (DOUBLE), FERM_GAP_TOT (DOUBLE), TIC_3601_PV (DOUBLE), FIC_4107_PV (DOUBLE), PI_4107_PV (DOUBLE), LIC_4204_VL (DOUBLE), FIC_4215_PV (DOUBLE), FI_6801_PV (DOUBLE), TI_4410_PV (DOUBLE), TI_4401_PV (DOUBLE), TI_DIFF_PV (DOUBLE), TI_SSDIFF_PV (DOUBLE), TI_4414_PV (DOUBLE), TV_2304_PV (DOUBLE), RECTDIFTMP (DOUBLE), PI_4501_PV (DOUBLE), PIC_4511_PV (DOUBLE), DTFIC_4506_S_PV (DOUBLE), FI_4505_PV (DOUBLE), PIC_4621_PV (DOUBLE), TI_4620_PV (DOUBLE), FIC_8401_PV (DOUBLE), TI_4619_PV (DOUBLE), FI_4613_PV (DOUBLE), LI_8401_PV (DOUBLE), LI_8422_PV (DOUBLE), LI_8433_PV (DOUBLE), II_6202_PV (DOUBLE), .\n",
      "\n",
      "Table 'plc_data_4' has columns: ID (INTEGER), Timestamp (DATETIME), Source_PLC (TEXT), FIC_6202_PV (DOUBLE), C2_DIFF_SPD (DOUBLE), C2_TORQ (DOUBLE), II_6203_PV (DOUBLE), FIC_6203_PV (DOUBLE), C3_DIFF_SPD (DOUBLE), C3_TORQ (DOUBLE), IT_6254_PV (DOUBLE), FIC_6254_PV (DOUBLE), C4_DIFF_SPD (DOUBLE), C4_TORQ (DOUBLE), FIC_161301_PV (DOUBLE), WT_161310_PV (DOUBLE), ZT_161310 (DOUBLE), FIC_161351_PV (DOUBLE), WT_161360_PV (DOUBLE), ZT_161360 (DOUBLE), LI_77101_PV (DOUBLE), LI_77102_PV (DOUBLE), FI_75802 (DOUBLE), TI_7107_PV (DOUBLE), TI_7103_PV (DOUBLE), FI_7102_PV (DOUBLE), PIC_7102_PV (DOUBLE), TIC_7311_PV (DOUBLE), TIC_7311_OUT (DOUBLE), FT_7306_PV (DOUBLE), FIC_6811_PV (DOUBLE), TI_7772_PV (DOUBLE), TI_7775_PV (DOUBLE), PI_7751_PV (DOUBLE), TI_7872_PV (DOUBLE), TI_7875_PV (DOUBLE), PI_7851_PV (DOUBLE), LI_12101_PV (DOUBLE), LI_12501_PV (DOUBLE), LI_12410_PV (DOUBLE), STEAMPERBEER (DOUBLE), TOT_STM_PERGAL (DOUBLE), TOTALCOOKWATER (DOUBLE), FT_70304_PV (DOUBLE), FT_70504_PV (DOUBLE), FT4613TOT (DOUBLE), FIC_6851_PV (DOUBLE), PT_7930_PV (DOUBLE), TV_4414_PV (DOUBLE), DI_4215_PV (DOUBLE), HT_7311_PV (DOUBLE), RATE_1401_PV (DOUBLE), LI_8403_PV (DOUBLE), LI_2301_PV (DOUBLE), FT4620_STM (DOUBLE), FT4107_STM (DOUBLE), C2_BOWL_CURRENT (DOUBLE), C3_BOWL_CURRENT (DOUBLE), SIEVEEFFIC (DOUBLE), FT1401TOT (DOUBLE), FT11301TOT (DOUBLE), FT_70104_PV (DOUBLE), TV_4414_VL (DOUBLE), .\n",
      "> Predicted SQL query: It appears there was a misunderstanding. The provided SQL query references a table named `equipment_downtime`, which is not listed among the available tables in the schema description. Let's generate a new natural language query and corresponding SQL query based on the provided tables.\n",
      "\n",
      "### New Natural Language Query:\n",
      "\"Retrieve all records from the last 24 hours in the 'plc_data_1' table, including the timestamp, source PLC, and any process variable values (e.g., AMM_3118_PV, TI_3112_PV).\"\n",
      "\n",
      "### Refined SQL Query:\n",
      "\n",
      "SELECT \n",
      "    Timestamp, \n",
      "    Source_PLC, \n",
      "    AMM_3118_PV, \n",
      "    TI_3112_PV\n",
      "FROM \n",
      "    plc_data_1\n",
      "WHERE \n",
      "    Timestamp >= NOW() - INTERVAL 1 DAY\n",
      "ORDER BY \n",
      "    Timestamp DESC;\n",
      "\n",
      "\n",
      "### Explanation:\n",
      "- **Timestamp**: The timestamp when the data was recorded.\n",
      "- **Source_PLC**: The source PLC from which the data was collected.\n",
      "- **AMM_3118_PV**: An example process variable value (you can include more as needed).\n",
      "- **TI_3112_PV**: Another example process variable value.\n",
      "\n",
      "This query selects all records from the `plc_data_1` table where the `Timestamp` is within the last 24 hours. It then orders the results by the `Timestamp` in descending order to show the most recent records first.\n",
      "\n",
      "If you need specific variables or additional details, please let me know!\n",
      "\u001b[1;3;38;2;155;135;227m> Running module output_component with input: \n",
      "output: It looks like there was a mix-up where the explanation and the actual SQL query were combined, causing a syntax error. Let's focus on the correct SQL query without the additional text.\n",
      "\n",
      "### Corrected ...\n",
      "\n",
      "\u001b[0m> Inferred SQL Query: It appears there was a misunderstanding. The provided SQL query references a table named `equipment_downtime`, which is not listed among the available tables in the schema description. Let's generate a new natural language query and corresponding SQL query based on the provided tables.\n",
      "\n",
      "### New Natural Language Query:\n",
      "\"Retrieve all records from the last 24 hours in the 'plc_data_1' table, including the timestamp, source PLC, and any process variable values (e.g., AMM_3118_PV, TI_3112_PV).\"\n",
      "\n",
      "### Refined SQL Query:\n",
      "\n",
      "SELECT \n",
      "    Timestamp, \n",
      "    Source_PLC, \n",
      "    AMM_3118_PV, \n",
      "    TI_3112_PV\n",
      "FROM \n",
      "    plc_data_1\n",
      "WHERE \n",
      "    Timestamp >= NOW() - INTERVAL 1 DAY\n",
      "ORDER BY \n",
      "    Timestamp DESC;\n",
      "\n",
      "\n",
      "### Explanation:\n",
      "- **Timestamp**: The timestamp when the data was recorded.\n",
      "- **Source_PLC**: The source PLC from which the data was collected.\n",
      "- **AMM_3118_PV**: An example process variable value (you can include more as needed).\n",
      "- **TI_3112_PV**: Another example process variable value.\n",
      "\n",
      "This query selects all records from the `plc_data_1` table where the `Timestamp` is within the last 24 hours. It then orders the results by the `Timestamp` in descending order to show the most recent records first.\n",
      "\n",
      "If you need specific variables or additional details, please let me know!\n",
      "> SQL Response: It looks like there was a mix-up where the explanation and the actual SQL query were combined, causing a syntax error. Let's focus on the correct SQL query without the additional text.\n",
      "\n",
      "### Corrected SQL Query:\n",
      "```sql\n",
      "SELECT \n",
      "    Timestamp, \n",
      "    Source_PLC, \n",
      "    AMM_3118_PV, \n",
      "    TI_3112_PV\n",
      "FROM \n",
      "    plc_data_1\n",
      "WHERE \n",
      "    Timestamp >= NOW() - INTERVAL 1 DAY\n",
      "ORDER BY \n",
      "    Timestamp DESC;\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- **Timestamp**: The timestamp when the data was recorded.\n",
      "- **Source_PLC**: The source PLC from which the data was collected.\n",
      "- **AMM_3118_PV**: An example process variable value (you can include more as needed).\n",
      "- **TI_3112_PV**: Another example process variable value.\n",
      "\n",
      "This query selects all records from the `plc_data_1` table where the `Timestamp` is within the last 24 hours. It then orders the results by the `Timestamp` in descending order to show the most recent records first.\n",
      "\n",
      "If you need specific variables or additional details, please let me know!\n",
      "It looks like there was a mix-up where the explanation and the actual SQL query were combined, causing a syntax error. Let's focus on the correct SQL query without the additional text.\n",
      "\n",
      "### Corrected SQL Query:\n",
      "```sql\n",
      "SELECT \n",
      "    Timestamp, \n",
      "    Source_PLC, \n",
      "    AMM_3118_PV, \n",
      "    TI_3112_PV\n",
      "FROM \n",
      "    plc_data_1\n",
      "WHERE \n",
      "    Timestamp >= NOW() - INTERVAL 1 DAY\n",
      "ORDER BY \n",
      "    Timestamp DESC;\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- **Timestamp**: The timestamp when the data was recorded.\n",
      "- **Source_PLC**: The source PLC from which the data was collected.\n",
      "- **AMM_3118_PV**: An example process variable value (you can include more as needed).\n",
      "- **TI_3112_PV**: Another example process variable value.\n",
      "\n",
      "This query selects all records from the `plc_data_1` table where the `Timestamp` is within the last 24 hours. It then orders the results by the `Timestamp` in descending order to show the most recent records first.\n",
      "\n",
      "If you need specific variables or additional details, please let me know!\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Downtime on equipment last 24 hours ?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factfinder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
